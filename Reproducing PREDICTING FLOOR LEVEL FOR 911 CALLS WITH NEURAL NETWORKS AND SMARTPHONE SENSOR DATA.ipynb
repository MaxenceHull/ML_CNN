{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = 'train_data/'\n",
    "TEST_DATA_PATH = 'test_data/'\n",
    "WINDOW_LENGTH = 3\n",
    "DEFAULT_FEATURES = ['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(path, features, flatten = True):\n",
    "    dataset = []\n",
    "    #features = ['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total']\n",
    "    for file_name in os.listdir(path):\n",
    "        if '.csv' in file_name:\n",
    "            df = pd.read_csv(path+ file_name)\n",
    "            dataset.append(df)\n",
    "\n",
    "    dataset = pd.concat(dataset)\n",
    "    dataset = dataset.reset_index()\n",
    "    dataset = dataset.reindex(np.random.permutation(dataset.index))\n",
    "\n",
    "    X = dataset[features]\n",
    "    Y = dataset[['indoors']]\n",
    "    X = X.as_matrix()\n",
    "    Y = Y.as_matrix()\n",
    "\n",
    "    for index, x in np.ndenumerate(Y):\n",
    "        if x not in [0,1,'0','1']:\n",
    "            X = np.delete(X, (index[0]), axis=0)\n",
    "            Y = np.delete(Y, (index[0]),axis=0)\n",
    "    new_X = []\n",
    "    new_Y = np.zeros((len(X) - WINDOW_LENGTH, 1))\n",
    "    arr_i = 0\n",
    "    side_size = int((WINDOW_LENGTH - 1) / 2)\n",
    "    for i in range(side_size, len(X)):\n",
    "        i_start = i - side_size\n",
    "        i_end = i + side_size +1\n",
    "        y_i = i\n",
    "        dps = X[i_start:i_end, :]\n",
    "        new_x = dps\n",
    "        if flatten:\n",
    "            new_x = dps.flatten()\n",
    "        new_y = Y[y_i]\n",
    "        if i_end >= len(X):\n",
    "            break\n",
    "        new_X.append(new_x)\n",
    "        new_Y[arr_i] = new_y\n",
    "        arr_i += 1\n",
    "    X = np.asarray(new_X)\n",
    "    Y = new_Y\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train I/O models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = getDataset(TRAIN_DATA_PATH, DEFAULT_FEATURES)\n",
    "X_test, Y_test = getDataset(TEST_DATA_PATH, DEFAULT_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "features_list.append(['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total'])\n",
    "features_list.append(\n",
    "    ['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total', 'baro_relative_altitude'])\n",
    "features_list.append(['gps_vertical_accuracy', 'gps_horizontal_accuracy'])\n",
    "features_list.append(['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed'])\n",
    "features_list.append(['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength'])\n",
    "features_list.append(['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total'])\n",
    "features_list.append(['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'baro_relative_altitude'])\n",
    "features_list.append(['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total', 'baro_pressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6486/6486 [==============================] - 1s 208us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total']0.8900709220225745\n",
      "6486/6486 [==============================] - 1s 222us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total', 'baro_relative_altitude']0.8908418131176057\n",
      "6486/6486 [==============================] - 1s 229us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy']0.8618563058160905\n",
      "6486/6486 [==============================] - 2s 242us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed']0.8777366635279636\n",
      "6486/6486 [==============================] - 2s 264us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength']0.8920752390681539\n",
      "6486/6486 [==============================] - 2s 269us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total']0.892229417187911\n",
      "6486/6486 [==============================] - 2s 273us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total', 'baro_pressure']0.8851372186614891\n"
     ]
    }
   ],
   "source": [
    "for features in features_list:\n",
    "    X_train, Y_train = getDataset(TRAIN_DATA_PATH, features)\n",
    "    X_test, Y_test = getDataset(TEST_DATA_PATH, features)\n",
    "    FFW = Sequential()\n",
    "\n",
    "    FFW.add(Dense(30, input_shape=(len(X_train[0]),)))\n",
    "    FFW.add(Activation('relu'))\n",
    "\n",
    "    FFW.add(Dense(18))\n",
    "    FFW.add(BatchNormalization(axis=1))\n",
    "    FFW.add(Dropout(0.7))\n",
    "    FFW.add(Activation('relu'))\n",
    "\n",
    "    FFW.add(Dense(1))\n",
    "    FFW.add(BatchNormalization(axis=1))\n",
    "    FFW.add(Activation('sigmoid'))\n",
    "\n",
    "    FFW.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(0.0001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    save_model_path = 'best_model_FFW'\n",
    "    modelcheckpoint = ModelCheckpoint(save_model_path, monitor = 'acc', verbose = 0, save_best_only = True)\n",
    "    history_FFW = FFW.fit(X_train, Y_train, batch_size=128, epochs = 600, validation_split = 0.1, callbacks=[modelcheckpoint],verbose=0)\n",
    "    FFW = load_model(save_model_path)\n",
    "    accuracy = FFW.evaluate(X_test, Y_test)[1]\n",
    "    print str(features) + str(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 30)                480       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 18)                558       \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 18)                72        \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 1)                 19        \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,133\n",
      "Trainable params: 1,095\n",
      "Non-trainable params: 38\n",
      "_________________________________________________________________\n",
      "Train on 4573 samples, validate on 509 samples\n",
      "Epoch 1/600\n",
      "4573/4573 [==============================] - 6s 1ms/step - loss: 0.6490 - acc: 0.6796 - val_loss: 0.5925 - val_acc: 0.7171\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.67964, saving model to best_model_FFW\n",
      "Epoch 2/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.6377 - acc: 0.6744 - val_loss: 0.5824 - val_acc: 0.7191\n",
      "\n",
      "Epoch 00002: acc did not improve\n",
      "Epoch 3/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.6305 - acc: 0.6908 - val_loss: 0.5737 - val_acc: 0.7191\n",
      "\n",
      "Epoch 00003: acc improved from 0.67964 to 0.69079, saving model to best_model_FFW\n",
      "Epoch 4/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.6002 - acc: 0.7142 - val_loss: 0.5666 - val_acc: 0.7348\n",
      "\n",
      "Epoch 00004: acc improved from 0.69079 to 0.71419, saving model to best_model_FFW\n",
      "Epoch 5/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.6034 - acc: 0.7085 - val_loss: 0.5604 - val_acc: 0.7623\n",
      "\n",
      "Epoch 00005: acc did not improve\n",
      "Epoch 6/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.5902 - acc: 0.7306 - val_loss: 0.5549 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00006: acc improved from 0.71419 to 0.73059, saving model to best_model_FFW\n",
      "Epoch 7/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5827 - acc: 0.7363 - val_loss: 0.5502 - val_acc: 0.8055\n",
      "\n",
      "Epoch 00007: acc improved from 0.73059 to 0.73628, saving model to best_model_FFW\n",
      "Epoch 8/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5760 - acc: 0.7361 - val_loss: 0.5459 - val_acc: 0.8035\n",
      "\n",
      "Epoch 00008: acc did not improve\n",
      "Epoch 9/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5753 - acc: 0.7402 - val_loss: 0.5422 - val_acc: 0.8035\n",
      "\n",
      "Epoch 00009: acc improved from 0.73628 to 0.74021, saving model to best_model_FFW\n",
      "Epoch 10/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5720 - acc: 0.7479 - val_loss: 0.5395 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00010: acc improved from 0.74021 to 0.74787, saving model to best_model_FFW\n",
      "Epoch 11/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.5601 - acc: 0.7612 - val_loss: 0.5372 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00011: acc improved from 0.74787 to 0.76121, saving model to best_model_FFW\n",
      "Epoch 12/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.5621 - acc: 0.7533 - val_loss: 0.5349 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00012: acc did not improve\n",
      "Epoch 13/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.5576 - acc: 0.7647 - val_loss: 0.5328 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00013: acc improved from 0.76121 to 0.76471, saving model to best_model_FFW\n",
      "Epoch 14/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.5498 - acc: 0.7697 - val_loss: 0.5303 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00014: acc improved from 0.76471 to 0.76974, saving model to best_model_FFW\n",
      "Epoch 15/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.5488 - acc: 0.7737 - val_loss: 0.5287 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00015: acc improved from 0.76974 to 0.77367, saving model to best_model_FFW\n",
      "Epoch 16/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5489 - acc: 0.7741 - val_loss: 0.5267 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00016: acc improved from 0.77367 to 0.77411, saving model to best_model_FFW\n",
      "Epoch 17/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.5508 - acc: 0.7737 - val_loss: 0.5239 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00017: acc did not improve\n",
      "Epoch 18/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.5413 - acc: 0.7835 - val_loss: 0.5224 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00018: acc improved from 0.77411 to 0.78351, saving model to best_model_FFW\n",
      "Epoch 19/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.5389 - acc: 0.7833 - val_loss: 0.5203 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00019: acc did not improve\n",
      "Epoch 20/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.5377 - acc: 0.7842 - val_loss: 0.5180 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00020: acc improved from 0.78351 to 0.78417, saving model to best_model_FFW\n",
      "Epoch 21/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.5377 - acc: 0.7870 - val_loss: 0.5162 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00021: acc improved from 0.78417 to 0.78701, saving model to best_model_FFW\n",
      "Epoch 22/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5304 - acc: 0.7872 - val_loss: 0.5152 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00022: acc improved from 0.78701 to 0.78723, saving model to best_model_FFW\n",
      "Epoch 23/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5337 - acc: 0.7888 - val_loss: 0.5139 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00023: acc improved from 0.78723 to 0.78876, saving model to best_model_FFW\n",
      "Epoch 24/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.5333 - acc: 0.7934 - val_loss: 0.5126 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00024: acc improved from 0.78876 to 0.79335, saving model to best_model_FFW\n",
      "Epoch 25/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.5275 - acc: 0.7888 - val_loss: 0.5113 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00025: acc did not improve\n",
      "Epoch 26/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.5288 - acc: 0.7905 - val_loss: 0.5096 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00026: acc did not improve\n",
      "Epoch 27/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5216 - acc: 0.7953 - val_loss: 0.5081 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00027: acc improved from 0.79335 to 0.79532, saving model to best_model_FFW\n",
      "Epoch 28/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.5263 - acc: 0.7920 - val_loss: 0.5062 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00028: acc did not improve\n",
      "Epoch 29/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.5289 - acc: 0.7901 - val_loss: 0.5043 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00029: acc did not improve\n",
      "Epoch 30/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.5255 - acc: 0.7953 - val_loss: 0.5037 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00030: acc improved from 0.79532 to 0.79532, saving model to best_model_FFW\n",
      "Epoch 31/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.5161 - acc: 0.8001 - val_loss: 0.5022 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00031: acc improved from 0.79532 to 0.80013, saving model to best_model_FFW\n",
      "Epoch 32/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.5205 - acc: 0.7995 - val_loss: 0.5000 - val_acc: 0.7996\n",
      "\n",
      "Epoch 00032: acc did not improve\n",
      "Epoch 33/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5190 - acc: 0.7975 - val_loss: 0.4987 - val_acc: 0.7996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: acc did not improve\n",
      "Epoch 34/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.5148 - acc: 0.8010 - val_loss: 0.4967 - val_acc: 0.7996\n",
      "\n",
      "Epoch 00034: acc improved from 0.80013 to 0.80101, saving model to best_model_FFW\n",
      "Epoch 35/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5135 - acc: 0.7990 - val_loss: 0.4940 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00035: acc did not improve\n",
      "Epoch 36/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.5117 - acc: 0.8041 - val_loss: 0.4925 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00036: acc improved from 0.80101 to 0.80407, saving model to best_model_FFW\n",
      "Epoch 37/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.5121 - acc: 0.8021 - val_loss: 0.4902 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00037: acc did not improve\n",
      "Epoch 38/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.5055 - acc: 0.8056 - val_loss: 0.4892 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00038: acc improved from 0.80407 to 0.80560, saving model to best_model_FFW\n",
      "Epoch 39/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5071 - acc: 0.8058 - val_loss: 0.4876 - val_acc: 0.8035\n",
      "\n",
      "Epoch 00039: acc improved from 0.80560 to 0.80582, saving model to best_model_FFW\n",
      "Epoch 40/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5035 - acc: 0.8034 - val_loss: 0.4862 - val_acc: 0.8035\n",
      "\n",
      "Epoch 00040: acc did not improve\n",
      "Epoch 41/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.5026 - acc: 0.8056 - val_loss: 0.4836 - val_acc: 0.8055\n",
      "\n",
      "Epoch 00041: acc did not improve\n",
      "Epoch 42/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.5062 - acc: 0.8056 - val_loss: 0.4820 - val_acc: 0.8055\n",
      "\n",
      "Epoch 00042: acc did not improve\n",
      "Epoch 43/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.5027 - acc: 0.8104 - val_loss: 0.4804 - val_acc: 0.8055\n",
      "\n",
      "Epoch 00043: acc improved from 0.80582 to 0.81041, saving model to best_model_FFW\n",
      "Epoch 44/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.5035 - acc: 0.8113 - val_loss: 0.4791 - val_acc: 0.8055\n",
      "\n",
      "Epoch 00044: acc improved from 0.81041 to 0.81128, saving model to best_model_FFW\n",
      "Epoch 45/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.5030 - acc: 0.8058 - val_loss: 0.4783 - val_acc: 0.8075\n",
      "\n",
      "Epoch 00045: acc did not improve\n",
      "Epoch 46/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.4985 - acc: 0.8122 - val_loss: 0.4772 - val_acc: 0.8114\n",
      "\n",
      "Epoch 00046: acc improved from 0.81128 to 0.81216, saving model to best_model_FFW\n",
      "Epoch 47/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.4971 - acc: 0.8091 - val_loss: 0.4743 - val_acc: 0.8094\n",
      "\n",
      "Epoch 00047: acc did not improve\n",
      "Epoch 48/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.4921 - acc: 0.8135 - val_loss: 0.4736 - val_acc: 0.8153\n",
      "\n",
      "Epoch 00048: acc improved from 0.81216 to 0.81347, saving model to best_model_FFW\n",
      "Epoch 49/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4966 - acc: 0.8108 - val_loss: 0.4716 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00049: acc did not improve\n",
      "Epoch 50/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4919 - acc: 0.8115 - val_loss: 0.4699 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00050: acc did not improve\n",
      "Epoch 51/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4924 - acc: 0.8130 - val_loss: 0.4677 - val_acc: 0.8251\n",
      "\n",
      "Epoch 00051: acc did not improve\n",
      "Epoch 52/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.4902 - acc: 0.8124 - val_loss: 0.4657 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00052: acc did not improve\n",
      "Epoch 53/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4893 - acc: 0.8181 - val_loss: 0.4641 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00053: acc improved from 0.81347 to 0.81806, saving model to best_model_FFW\n",
      "Epoch 54/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.4884 - acc: 0.8117 - val_loss: 0.4640 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00054: acc did not improve\n",
      "Epoch 55/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.4817 - acc: 0.8187 - val_loss: 0.4641 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00055: acc improved from 0.81806 to 0.81872, saving model to best_model_FFW\n",
      "Epoch 56/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4829 - acc: 0.8185 - val_loss: 0.4605 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00056: acc did not improve\n",
      "Epoch 57/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4865 - acc: 0.8200 - val_loss: 0.4602 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00057: acc improved from 0.81872 to 0.82003, saving model to best_model_FFW\n",
      "Epoch 58/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.4836 - acc: 0.8222 - val_loss: 0.4584 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00058: acc improved from 0.82003 to 0.82222, saving model to best_model_FFW\n",
      "Epoch 59/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.4799 - acc: 0.8202 - val_loss: 0.4560 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00059: acc did not improve\n",
      "Epoch 60/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.4790 - acc: 0.8209 - val_loss: 0.4555 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00060: acc did not improve\n",
      "Epoch 61/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4723 - acc: 0.8281 - val_loss: 0.4568 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00061: acc improved from 0.82222 to 0.82812, saving model to best_model_FFW\n",
      "Epoch 62/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4771 - acc: 0.8227 - val_loss: 0.4524 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00062: acc did not improve\n",
      "Epoch 63/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4751 - acc: 0.8266 - val_loss: 0.4479 - val_acc: 0.8428\n",
      "\n",
      "Epoch 00063: acc did not improve\n",
      "Epoch 64/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4693 - acc: 0.8301 - val_loss: 0.4465 - val_acc: 0.8428\n",
      "\n",
      "Epoch 00064: acc improved from 0.82812 to 0.83009, saving model to best_model_FFW\n",
      "Epoch 65/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.4715 - acc: 0.8270 - val_loss: 0.4466 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00065: acc did not improve\n",
      "Epoch 66/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4637 - acc: 0.8283 - val_loss: 0.4405 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00066: acc did not improve\n",
      "Epoch 67/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4665 - acc: 0.8288 - val_loss: 0.4404 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00067: acc did not improve\n",
      "Epoch 68/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4600 - acc: 0.8358 - val_loss: 0.4364 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00068: acc improved from 0.83009 to 0.83578, saving model to best_model_FFW\n",
      "Epoch 69/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4646 - acc: 0.8307 - val_loss: 0.4334 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00069: acc did not improve\n",
      "Epoch 70/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4588 - acc: 0.8380 - val_loss: 0.4322 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00070: acc improved from 0.83578 to 0.83796, saving model to best_model_FFW\n",
      "Epoch 71/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4587 - acc: 0.8371 - val_loss: 0.4288 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00071: acc did not improve\n",
      "Epoch 72/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4597 - acc: 0.8428 - val_loss: 0.4325 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00072: acc improved from 0.83796 to 0.84277, saving model to best_model_FFW\n",
      "Epoch 73/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4599 - acc: 0.8327 - val_loss: 0.4278 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00073: acc did not improve\n",
      "Epoch 74/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4547 - acc: 0.8364 - val_loss: 0.4286 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00074: acc did not improve\n",
      "Epoch 75/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4495 - acc: 0.8423 - val_loss: 0.4270 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00075: acc did not improve\n",
      "Epoch 76/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4562 - acc: 0.8380 - val_loss: 0.4247 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00076: acc did not improve\n",
      "Epoch 77/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4499 - acc: 0.8395 - val_loss: 0.4228 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00077: acc did not improve\n",
      "Epoch 78/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4509 - acc: 0.8408 - val_loss: 0.4223 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00078: acc did not improve\n",
      "Epoch 79/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4475 - acc: 0.8406 - val_loss: 0.4211 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00079: acc did not improve\n",
      "Epoch 80/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4530 - acc: 0.8362 - val_loss: 0.4155 - val_acc: 0.8782\n",
      "\n",
      "Epoch 00080: acc did not improve\n",
      "Epoch 81/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.4424 - acc: 0.8478 - val_loss: 0.4186 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00081: acc improved from 0.84277 to 0.84780, saving model to best_model_FFW\n",
      "Epoch 82/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4394 - acc: 0.8474 - val_loss: 0.4203 - val_acc: 0.8782\n",
      "\n",
      "Epoch 00082: acc did not improve\n",
      "Epoch 83/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4356 - acc: 0.8482 - val_loss: 0.4155 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00083: acc improved from 0.84780 to 0.84824, saving model to best_model_FFW\n",
      "Epoch 84/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.4410 - acc: 0.8458 - val_loss: 0.4088 - val_acc: 0.8782\n",
      "\n",
      "Epoch 00084: acc did not improve\n",
      "Epoch 85/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4346 - acc: 0.8531 - val_loss: 0.4104 - val_acc: 0.8782\n",
      "\n",
      "Epoch 00085: acc improved from 0.84824 to 0.85305, saving model to best_model_FFW\n",
      "Epoch 86/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.4365 - acc: 0.8504 - val_loss: 0.4042 - val_acc: 0.8821\n",
      "\n",
      "Epoch 00086: acc did not improve\n",
      "Epoch 87/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.4358 - acc: 0.8520 - val_loss: 0.4009 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00087: acc did not improve\n",
      "Epoch 88/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.4384 - acc: 0.8509 - val_loss: 0.3999 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00088: acc did not improve\n",
      "Epoch 89/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.4360 - acc: 0.8471 - val_loss: 0.3955 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00089: acc did not improve\n",
      "Epoch 90/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4315 - acc: 0.8550 - val_loss: 0.3986 - val_acc: 0.8821\n",
      "\n",
      "Epoch 00090: acc improved from 0.85305 to 0.85502, saving model to best_model_FFW\n",
      "Epoch 91/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.4312 - acc: 0.8576 - val_loss: 0.3993 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00091: acc improved from 0.85502 to 0.85764, saving model to best_model_FFW\n",
      "Epoch 92/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.4303 - acc: 0.8522 - val_loss: 0.3934 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00092: acc did not improve\n",
      "Epoch 93/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.4275 - acc: 0.8548 - val_loss: 0.3900 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00093: acc did not improve\n",
      "Epoch 94/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.4263 - acc: 0.8607 - val_loss: 0.3909 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00094: acc improved from 0.85764 to 0.86070, saving model to best_model_FFW\n",
      "Epoch 95/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.4261 - acc: 0.8539 - val_loss: 0.3881 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00095: acc did not improve\n",
      "Epoch 96/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.4237 - acc: 0.8555 - val_loss: 0.3888 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00096: acc did not improve\n",
      "Epoch 97/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.4235 - acc: 0.8546 - val_loss: 0.3845 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00097: acc did not improve\n",
      "Epoch 98/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4188 - acc: 0.8622 - val_loss: 0.3871 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00098: acc improved from 0.86070 to 0.86223, saving model to best_model_FFW\n",
      "Epoch 99/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4215 - acc: 0.8548 - val_loss: 0.3817 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00099: acc did not improve\n",
      "Epoch 100/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.4149 - acc: 0.8633 - val_loss: 0.3846 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00100: acc improved from 0.86223 to 0.86333, saving model to best_model_FFW\n",
      "Epoch 101/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.4175 - acc: 0.8605 - val_loss: 0.3774 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00101: acc did not improve\n",
      "Epoch 102/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.4183 - acc: 0.8600 - val_loss: 0.3766 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00102: acc did not improve\n",
      "Epoch 103/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.4123 - acc: 0.8692 - val_loss: 0.3740 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00103: acc improved from 0.86333 to 0.86923, saving model to best_model_FFW\n",
      "Epoch 104/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4164 - acc: 0.8666 - val_loss: 0.3737 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00104: acc did not improve\n",
      "Epoch 105/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4123 - acc: 0.8640 - val_loss: 0.3736 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00105: acc did not improve\n",
      "Epoch 106/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.4128 - acc: 0.8616 - val_loss: 0.3796 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00106: acc did not improve\n",
      "Epoch 107/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4070 - acc: 0.8710 - val_loss: 0.3744 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00107: acc improved from 0.86923 to 0.87098, saving model to best_model_FFW\n",
      "Epoch 108/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.4118 - acc: 0.8664 - val_loss: 0.3759 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00108: acc did not improve\n",
      "Epoch 109/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.4051 - acc: 0.8723 - val_loss: 0.3683 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00109: acc improved from 0.87098 to 0.87229, saving model to best_model_FFW\n",
      "Epoch 110/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4094 - acc: 0.8666 - val_loss: 0.3725 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00110: acc did not improve\n",
      "Epoch 111/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.4032 - acc: 0.8738 - val_loss: 0.3727 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00111: acc improved from 0.87229 to 0.87382, saving model to best_model_FFW\n",
      "Epoch 112/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.4108 - acc: 0.8646 - val_loss: 0.3703 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00112: acc did not improve\n",
      "Epoch 113/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.4040 - acc: 0.8710 - val_loss: 0.3699 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00113: acc did not improve\n",
      "Epoch 114/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.4029 - acc: 0.8701 - val_loss: 0.3678 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00114: acc did not improve\n",
      "Epoch 115/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.4016 - acc: 0.8703 - val_loss: 0.3672 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00115: acc did not improve\n",
      "Epoch 116/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.4031 - acc: 0.8708 - val_loss: 0.3694 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00116: acc did not improve\n",
      "Epoch 117/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.4032 - acc: 0.8751 - val_loss: 0.3675 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00117: acc improved from 0.87382 to 0.87514, saving model to best_model_FFW\n",
      "Epoch 118/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.4027 - acc: 0.8660 - val_loss: 0.3599 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00118: acc did not improve\n",
      "Epoch 119/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.4013 - acc: 0.8732 - val_loss: 0.3601 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00119: acc did not improve\n",
      "Epoch 120/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3971 - acc: 0.8690 - val_loss: 0.3584 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00120: acc did not improve\n",
      "Epoch 121/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.3978 - acc: 0.8679 - val_loss: 0.3548 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00121: acc did not improve\n",
      "Epoch 122/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3967 - acc: 0.8782 - val_loss: 0.3577 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00122: acc improved from 0.87514 to 0.87820, saving model to best_model_FFW\n",
      "Epoch 123/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3969 - acc: 0.8732 - val_loss: 0.3535 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00123: acc did not improve\n",
      "Epoch 124/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3956 - acc: 0.8769 - val_loss: 0.3555 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00124: acc did not improve\n",
      "Epoch 125/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.3961 - acc: 0.8732 - val_loss: 0.3518 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00125: acc did not improve\n",
      "Epoch 126/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3878 - acc: 0.8819 - val_loss: 0.3514 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00126: acc improved from 0.87820 to 0.88192, saving model to best_model_FFW\n",
      "Epoch 127/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3910 - acc: 0.8749 - val_loss: 0.3501 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00127: acc did not improve\n",
      "Epoch 128/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3949 - acc: 0.8747 - val_loss: 0.3499 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00128: acc did not improve\n",
      "Epoch 129/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.3882 - acc: 0.8819 - val_loss: 0.3491 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00129: acc improved from 0.88192 to 0.88192, saving model to best_model_FFW\n",
      "Epoch 130/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.3890 - acc: 0.8789 - val_loss: 0.3468 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00130: acc did not improve\n",
      "Epoch 131/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3895 - acc: 0.8786 - val_loss: 0.3470 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00131: acc did not improve\n",
      "Epoch 132/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.3875 - acc: 0.8780 - val_loss: 0.3445 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00132: acc did not improve\n",
      "Epoch 133/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3847 - acc: 0.8845 - val_loss: 0.3485 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00133: acc improved from 0.88192 to 0.88454, saving model to best_model_FFW\n",
      "Epoch 134/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.3829 - acc: 0.8830 - val_loss: 0.3480 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00134: acc did not improve\n",
      "Epoch 135/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.3886 - acc: 0.8780 - val_loss: 0.3474 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00135: acc did not improve\n",
      "Epoch 136/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3908 - acc: 0.8764 - val_loss: 0.3429 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00136: acc did not improve\n",
      "Epoch 137/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3887 - acc: 0.8815 - val_loss: 0.3449 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00137: acc did not improve\n",
      "Epoch 138/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3802 - acc: 0.8815 - val_loss: 0.3463 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00138: acc did not improve\n",
      "Epoch 139/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3858 - acc: 0.8789 - val_loss: 0.3418 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00139: acc did not improve\n",
      "Epoch 140/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.3843 - acc: 0.8778 - val_loss: 0.3431 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00140: acc did not improve\n",
      "Epoch 141/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3799 - acc: 0.8880 - val_loss: 0.3427 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00141: acc improved from 0.88454 to 0.88804, saving model to best_model_FFW\n",
      "Epoch 142/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3830 - acc: 0.8773 - val_loss: 0.3400 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00142: acc did not improve\n",
      "Epoch 143/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.3771 - acc: 0.8856 - val_loss: 0.3417 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00143: acc did not improve\n",
      "Epoch 144/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3763 - acc: 0.8865 - val_loss: 0.3397 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00144: acc did not improve\n",
      "Epoch 145/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.3789 - acc: 0.8865 - val_loss: 0.3369 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00145: acc did not improve\n",
      "Epoch 146/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3817 - acc: 0.8797 - val_loss: 0.3337 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00146: acc did not improve\n",
      "Epoch 147/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.3760 - acc: 0.8793 - val_loss: 0.3322 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00147: acc did not improve\n",
      "Epoch 148/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.3733 - acc: 0.8859 - val_loss: 0.3324 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00148: acc did not improve\n",
      "Epoch 149/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.3764 - acc: 0.8856 - val_loss: 0.3370 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00149: acc did not improve\n",
      "Epoch 150/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3739 - acc: 0.8887 - val_loss: 0.3363 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00150: acc improved from 0.88804 to 0.88869, saving model to best_model_FFW\n",
      "Epoch 151/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3758 - acc: 0.8854 - val_loss: 0.3353 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00151: acc did not improve\n",
      "Epoch 152/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3756 - acc: 0.8874 - val_loss: 0.3333 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00152: acc did not improve\n",
      "Epoch 153/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3703 - acc: 0.8883 - val_loss: 0.3300 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00153: acc did not improve\n",
      "Epoch 154/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.3712 - acc: 0.8898 - val_loss: 0.3292 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00154: acc improved from 0.88869 to 0.88979, saving model to best_model_FFW\n",
      "Epoch 155/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3688 - acc: 0.8880 - val_loss: 0.3259 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00155: acc did not improve\n",
      "Epoch 156/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3697 - acc: 0.8837 - val_loss: 0.3289 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00156: acc did not improve\n",
      "Epoch 157/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3658 - acc: 0.8885 - val_loss: 0.3283 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00157: acc did not improve\n",
      "Epoch 158/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.3693 - acc: 0.8874 - val_loss: 0.3261 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00158: acc did not improve\n",
      "Epoch 159/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3723 - acc: 0.8837 - val_loss: 0.3297 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00159: acc did not improve\n",
      "Epoch 160/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3636 - acc: 0.8898 - val_loss: 0.3294 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00160: acc improved from 0.88979 to 0.88979, saving model to best_model_FFW\n",
      "Epoch 161/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3727 - acc: 0.8850 - val_loss: 0.3238 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00161: acc did not improve\n",
      "Epoch 162/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.3713 - acc: 0.8799 - val_loss: 0.3226 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00162: acc did not improve\n",
      "Epoch 163/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3671 - acc: 0.8867 - val_loss: 0.3185 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00163: acc did not improve\n",
      "Epoch 164/600\n",
      "4573/4573 [==============================] - 0s 37us/step - loss: 0.3659 - acc: 0.8878 - val_loss: 0.3235 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00164: acc did not improve\n",
      "Epoch 165/600\n",
      "4573/4573 [==============================] - 0s 36us/step - loss: 0.3590 - acc: 0.8953 - val_loss: 0.3262 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00165: acc improved from 0.88979 to 0.89525, saving model to best_model_FFW\n",
      "Epoch 166/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3614 - acc: 0.8887 - val_loss: 0.3240 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00166: acc did not improve\n",
      "Epoch 167/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.3645 - acc: 0.8922 - val_loss: 0.3226 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00167: acc did not improve\n",
      "Epoch 168/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3591 - acc: 0.8891 - val_loss: 0.3235 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00168: acc did not improve\n",
      "Epoch 169/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3612 - acc: 0.8896 - val_loss: 0.3188 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00169: acc did not improve\n",
      "Epoch 170/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3582 - acc: 0.8922 - val_loss: 0.3176 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00170: acc did not improve\n",
      "Epoch 171/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3648 - acc: 0.8909 - val_loss: 0.3146 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00171: acc did not improve\n",
      "Epoch 172/600\n",
      "4573/4573 [==============================] - 0s 44us/step - loss: 0.3623 - acc: 0.8880 - val_loss: 0.3118 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00172: acc did not improve\n",
      "Epoch 173/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3608 - acc: 0.8904 - val_loss: 0.3175 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00173: acc did not improve\n",
      "Epoch 174/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3629 - acc: 0.8848 - val_loss: 0.3170 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00174: acc did not improve\n",
      "Epoch 175/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3586 - acc: 0.8918 - val_loss: 0.3163 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00175: acc did not improve\n",
      "Epoch 176/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3492 - acc: 0.8963 - val_loss: 0.3121 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00176: acc improved from 0.89525 to 0.89635, saving model to best_model_FFW\n",
      "Epoch 177/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3571 - acc: 0.8885 - val_loss: 0.3111 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00177: acc did not improve\n",
      "Epoch 178/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3542 - acc: 0.8920 - val_loss: 0.3118 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00178: acc did not improve\n",
      "Epoch 179/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3533 - acc: 0.8937 - val_loss: 0.3109 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00179: acc did not improve\n",
      "Epoch 180/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3531 - acc: 0.8926 - val_loss: 0.3119 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00180: acc did not improve\n",
      "Epoch 181/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3518 - acc: 0.8907 - val_loss: 0.3134 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00181: acc did not improve\n",
      "Epoch 182/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3546 - acc: 0.8961 - val_loss: 0.3134 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00182: acc did not improve\n",
      "Epoch 183/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3477 - acc: 0.8955 - val_loss: 0.3156 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00183: acc did not improve\n",
      "Epoch 184/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3543 - acc: 0.8957 - val_loss: 0.3109 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00184: acc did not improve\n",
      "Epoch 185/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3481 - acc: 0.9009 - val_loss: 0.3115 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00185: acc improved from 0.89635 to 0.90094, saving model to best_model_FFW\n",
      "Epoch 186/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3509 - acc: 0.8918 - val_loss: 0.3083 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00186: acc did not improve\n",
      "Epoch 187/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3453 - acc: 0.8946 - val_loss: 0.3042 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00187: acc did not improve\n",
      "Epoch 188/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3481 - acc: 0.8972 - val_loss: 0.3055 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00188: acc did not improve\n",
      "Epoch 189/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3493 - acc: 0.8966 - val_loss: 0.3089 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00189: acc did not improve\n",
      "Epoch 190/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3449 - acc: 0.8957 - val_loss: 0.3071 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00190: acc did not improve\n",
      "Epoch 191/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3439 - acc: 0.8972 - val_loss: 0.3029 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00191: acc did not improve\n",
      "Epoch 192/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3517 - acc: 0.8900 - val_loss: 0.3040 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00192: acc did not improve\n",
      "Epoch 193/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3499 - acc: 0.8928 - val_loss: 0.3043 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00193: acc did not improve\n",
      "Epoch 194/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3456 - acc: 0.8946 - val_loss: 0.3036 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00194: acc did not improve\n",
      "Epoch 195/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3445 - acc: 0.8974 - val_loss: 0.3013 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00195: acc did not improve\n",
      "Epoch 196/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3476 - acc: 0.8968 - val_loss: 0.3023 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00196: acc did not improve\n",
      "Epoch 197/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3429 - acc: 0.8948 - val_loss: 0.3036 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00197: acc did not improve\n",
      "Epoch 198/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3427 - acc: 0.8983 - val_loss: 0.3057 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00198: acc did not improve\n",
      "Epoch 199/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3406 - acc: 0.8961 - val_loss: 0.3035 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00199: acc did not improve\n",
      "Epoch 200/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3419 - acc: 0.8979 - val_loss: 0.2981 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00200: acc did not improve\n",
      "Epoch 201/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3372 - acc: 0.9009 - val_loss: 0.2934 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00201: acc improved from 0.90094 to 0.90094, saving model to best_model_FFW\n",
      "Epoch 202/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3423 - acc: 0.8931 - val_loss: 0.2950 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00202: acc did not improve\n",
      "Epoch 203/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3367 - acc: 0.9031 - val_loss: 0.2899 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00203: acc improved from 0.90094 to 0.90313, saving model to best_model_FFW\n",
      "Epoch 204/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3470 - acc: 0.8998 - val_loss: 0.2919 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00204: acc did not improve\n",
      "Epoch 205/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3321 - acc: 0.9042 - val_loss: 0.2950 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00205: acc improved from 0.90313 to 0.90422, saving model to best_model_FFW\n",
      "Epoch 206/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3432 - acc: 0.8926 - val_loss: 0.2975 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00206: acc did not improve\n",
      "Epoch 207/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3331 - acc: 0.9025 - val_loss: 0.2989 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00207: acc did not improve\n",
      "Epoch 208/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3377 - acc: 0.8990 - val_loss: 0.2965 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00208: acc did not improve\n",
      "Epoch 209/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3405 - acc: 0.8974 - val_loss: 0.2939 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00209: acc did not improve\n",
      "Epoch 210/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3378 - acc: 0.8972 - val_loss: 0.2898 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00210: acc did not improve\n",
      "Epoch 211/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3493 - acc: 0.8946 - val_loss: 0.2899 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00211: acc did not improve\n",
      "Epoch 212/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3348 - acc: 0.9005 - val_loss: 0.2932 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00212: acc did not improve\n",
      "Epoch 213/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3382 - acc: 0.9003 - val_loss: 0.2910 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00213: acc did not improve\n",
      "Epoch 214/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3371 - acc: 0.9023 - val_loss: 0.2895 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00214: acc did not improve\n",
      "Epoch 215/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3373 - acc: 0.8992 - val_loss: 0.2945 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00215: acc did not improve\n",
      "Epoch 216/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3342 - acc: 0.8994 - val_loss: 0.2909 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00216: acc did not improve\n",
      "Epoch 217/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3326 - acc: 0.9033 - val_loss: 0.2920 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00217: acc did not improve\n",
      "Epoch 218/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3367 - acc: 0.8968 - val_loss: 0.2871 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00218: acc did not improve\n",
      "Epoch 219/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3367 - acc: 0.8966 - val_loss: 0.2906 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00219: acc did not improve\n",
      "Epoch 220/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3306 - acc: 0.9023 - val_loss: 0.2883 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00220: acc did not improve\n",
      "Epoch 221/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3313 - acc: 0.9016 - val_loss: 0.2899 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00221: acc did not improve\n",
      "Epoch 222/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3347 - acc: 0.8983 - val_loss: 0.2869 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00222: acc did not improve\n",
      "Epoch 223/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3302 - acc: 0.9025 - val_loss: 0.2877 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00223: acc did not improve\n",
      "Epoch 224/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3302 - acc: 0.9023 - val_loss: 0.2841 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00224: acc did not improve\n",
      "Epoch 225/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3338 - acc: 0.9003 - val_loss: 0.2813 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00225: acc did not improve\n",
      "Epoch 226/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3274 - acc: 0.9020 - val_loss: 0.2808 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00226: acc did not improve\n",
      "Epoch 227/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3330 - acc: 0.9001 - val_loss: 0.2794 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00227: acc did not improve\n",
      "Epoch 228/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3279 - acc: 0.8985 - val_loss: 0.2816 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00228: acc did not improve\n",
      "Epoch 229/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3244 - acc: 0.9012 - val_loss: 0.2797 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00229: acc did not improve\n",
      "Epoch 230/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3276 - acc: 0.9029 - val_loss: 0.2797 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00230: acc did not improve\n",
      "Epoch 231/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3331 - acc: 0.9027 - val_loss: 0.2841 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00231: acc did not improve\n",
      "Epoch 232/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3281 - acc: 0.9009 - val_loss: 0.2831 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00232: acc did not improve\n",
      "Epoch 233/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3244 - acc: 0.9058 - val_loss: 0.2843 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00233: acc improved from 0.90422 to 0.90575, saving model to best_model_FFW\n",
      "Epoch 234/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3282 - acc: 0.9003 - val_loss: 0.2809 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00234: acc did not improve\n",
      "Epoch 235/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3364 - acc: 0.8979 - val_loss: 0.2766 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00235: acc did not improve\n",
      "Epoch 236/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3222 - acc: 0.9090 - val_loss: 0.2798 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00236: acc improved from 0.90575 to 0.90903, saving model to best_model_FFW\n",
      "Epoch 237/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3273 - acc: 0.9023 - val_loss: 0.2853 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00237: acc did not improve\n",
      "Epoch 238/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3238 - acc: 0.9025 - val_loss: 0.2810 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00238: acc did not improve\n",
      "Epoch 239/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3256 - acc: 0.9014 - val_loss: 0.2802 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00239: acc did not improve\n",
      "Epoch 240/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3252 - acc: 0.9047 - val_loss: 0.2767 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00240: acc did not improve\n",
      "Epoch 241/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3199 - acc: 0.9062 - val_loss: 0.2764 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00241: acc did not improve\n",
      "Epoch 242/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3172 - acc: 0.9075 - val_loss: 0.2748 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00242: acc did not improve\n",
      "Epoch 243/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3250 - acc: 0.9047 - val_loss: 0.2763 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00243: acc did not improve\n",
      "Epoch 244/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3207 - acc: 0.8994 - val_loss: 0.2807 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00244: acc did not improve\n",
      "Epoch 245/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3232 - acc: 0.9020 - val_loss: 0.2801 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00245: acc did not improve\n",
      "Epoch 246/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3225 - acc: 0.9027 - val_loss: 0.2775 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00246: acc did not improve\n",
      "Epoch 247/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3186 - acc: 0.9082 - val_loss: 0.2760 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00247: acc did not improve\n",
      "Epoch 248/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3242 - acc: 0.9023 - val_loss: 0.2796 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00248: acc did not improve\n",
      "Epoch 249/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.3212 - acc: 0.9062 - val_loss: 0.2743 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00249: acc did not improve\n",
      "Epoch 250/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3238 - acc: 0.9049 - val_loss: 0.2744 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00250: acc did not improve\n",
      "Epoch 251/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3178 - acc: 0.9062 - val_loss: 0.2772 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00251: acc did not improve\n",
      "Epoch 252/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3248 - acc: 0.9047 - val_loss: 0.2759 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00252: acc did not improve\n",
      "Epoch 253/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.3196 - acc: 0.9068 - val_loss: 0.2725 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00253: acc did not improve\n",
      "Epoch 254/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.3182 - acc: 0.9047 - val_loss: 0.2716 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00254: acc did not improve\n",
      "Epoch 255/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3217 - acc: 0.9014 - val_loss: 0.2718 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00255: acc did not improve\n",
      "Epoch 256/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3193 - acc: 0.9068 - val_loss: 0.2741 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00256: acc did not improve\n",
      "Epoch 257/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.3183 - acc: 0.9027 - val_loss: 0.2757 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00257: acc did not improve\n",
      "Epoch 258/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.3196 - acc: 0.9042 - val_loss: 0.2720 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00258: acc did not improve\n",
      "Epoch 259/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3183 - acc: 0.9058 - val_loss: 0.2701 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00259: acc did not improve\n",
      "Epoch 260/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3157 - acc: 0.9090 - val_loss: 0.2738 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00260: acc did not improve\n",
      "Epoch 261/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.3187 - acc: 0.9082 - val_loss: 0.2711 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00261: acc did not improve\n",
      "Epoch 262/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3080 - acc: 0.9134 - val_loss: 0.2676 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00262: acc improved from 0.90903 to 0.91340, saving model to best_model_FFW\n",
      "Epoch 263/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3153 - acc: 0.9103 - val_loss: 0.2668 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00263: acc did not improve\n",
      "Epoch 264/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3178 - acc: 0.9062 - val_loss: 0.2668 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00264: acc did not improve\n",
      "Epoch 265/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3162 - acc: 0.9051 - val_loss: 0.2682 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00265: acc did not improve\n",
      "Epoch 266/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3198 - acc: 0.9079 - val_loss: 0.2676 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00266: acc did not improve\n",
      "Epoch 267/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3150 - acc: 0.9060 - val_loss: 0.2719 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00267: acc did not improve\n",
      "Epoch 268/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3170 - acc: 0.9062 - val_loss: 0.2677 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00268: acc did not improve\n",
      "Epoch 269/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3145 - acc: 0.9051 - val_loss: 0.2679 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00269: acc did not improve\n",
      "Epoch 270/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3081 - acc: 0.9112 - val_loss: 0.2690 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00270: acc did not improve\n",
      "Epoch 271/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.3097 - acc: 0.9090 - val_loss: 0.2648 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00271: acc did not improve\n",
      "Epoch 272/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3108 - acc: 0.9108 - val_loss: 0.2683 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00272: acc did not improve\n",
      "Epoch 273/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3121 - acc: 0.9092 - val_loss: 0.2658 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00273: acc did not improve\n",
      "Epoch 274/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3179 - acc: 0.9029 - val_loss: 0.2632 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00274: acc did not improve\n",
      "Epoch 275/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3080 - acc: 0.9079 - val_loss: 0.2654 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00275: acc did not improve\n",
      "Epoch 276/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3122 - acc: 0.9082 - val_loss: 0.2650 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00276: acc did not improve\n",
      "Epoch 277/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3101 - acc: 0.9075 - val_loss: 0.2610 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00277: acc did not improve\n",
      "Epoch 278/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3087 - acc: 0.9099 - val_loss: 0.2633 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00278: acc did not improve\n",
      "Epoch 279/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3099 - acc: 0.9075 - val_loss: 0.2604 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00279: acc did not improve\n",
      "Epoch 280/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3055 - acc: 0.9088 - val_loss: 0.2648 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00280: acc did not improve\n",
      "Epoch 281/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3148 - acc: 0.9125 - val_loss: 0.2622 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00281: acc did not improve\n",
      "Epoch 282/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3129 - acc: 0.9071 - val_loss: 0.2629 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00282: acc did not improve\n",
      "Epoch 283/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3172 - acc: 0.9025 - val_loss: 0.2580 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00283: acc did not improve\n",
      "Epoch 284/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3035 - acc: 0.9114 - val_loss: 0.2612 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00284: acc did not improve\n",
      "Epoch 285/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3084 - acc: 0.9088 - val_loss: 0.2637 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00285: acc did not improve\n",
      "Epoch 286/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3019 - acc: 0.9099 - val_loss: 0.2630 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00286: acc did not improve\n",
      "Epoch 287/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3076 - acc: 0.9053 - val_loss: 0.2613 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00287: acc did not improve\n",
      "Epoch 288/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3072 - acc: 0.9075 - val_loss: 0.2584 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00288: acc did not improve\n",
      "Epoch 289/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3071 - acc: 0.9106 - val_loss: 0.2633 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00289: acc did not improve\n",
      "Epoch 290/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3063 - acc: 0.9101 - val_loss: 0.2613 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00290: acc did not improve\n",
      "Epoch 291/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3108 - acc: 0.9053 - val_loss: 0.2602 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00291: acc did not improve\n",
      "Epoch 292/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3011 - acc: 0.9082 - val_loss: 0.2582 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00292: acc did not improve\n",
      "Epoch 293/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3065 - acc: 0.9090 - val_loss: 0.2583 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00293: acc did not improve\n",
      "Epoch 294/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3037 - acc: 0.9117 - val_loss: 0.2585 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00294: acc did not improve\n",
      "Epoch 295/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3073 - acc: 0.9071 - val_loss: 0.2567 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00295: acc did not improve\n",
      "Epoch 296/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3060 - acc: 0.9053 - val_loss: 0.2578 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00296: acc did not improve\n",
      "Epoch 297/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3052 - acc: 0.9121 - val_loss: 0.2562 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00297: acc did not improve\n",
      "Epoch 298/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2962 - acc: 0.9167 - val_loss: 0.2582 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00298: acc improved from 0.91340 to 0.91668, saving model to best_model_FFW\n",
      "Epoch 299/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3054 - acc: 0.9132 - val_loss: 0.2536 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00299: acc did not improve\n",
      "Epoch 300/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3092 - acc: 0.9138 - val_loss: 0.2573 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00300: acc did not improve\n",
      "Epoch 301/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2995 - acc: 0.9097 - val_loss: 0.2562 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00301: acc did not improve\n",
      "Epoch 302/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2990 - acc: 0.9147 - val_loss: 0.2556 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00302: acc did not improve\n",
      "Epoch 303/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3007 - acc: 0.9099 - val_loss: 0.2539 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00303: acc did not improve\n",
      "Epoch 304/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2926 - acc: 0.9156 - val_loss: 0.2564 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00304: acc did not improve\n",
      "Epoch 305/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3041 - acc: 0.9103 - val_loss: 0.2566 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00305: acc did not improve\n",
      "Epoch 306/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3031 - acc: 0.9112 - val_loss: 0.2545 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00306: acc did not improve\n",
      "Epoch 307/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2988 - acc: 0.9112 - val_loss: 0.2543 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00307: acc did not improve\n",
      "Epoch 308/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2982 - acc: 0.9121 - val_loss: 0.2517 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00308: acc did not improve\n",
      "Epoch 309/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3043 - acc: 0.9068 - val_loss: 0.2528 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00309: acc did not improve\n",
      "Epoch 310/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2949 - acc: 0.9132 - val_loss: 0.2550 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00310: acc did not improve\n",
      "Epoch 311/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2984 - acc: 0.9130 - val_loss: 0.2561 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00311: acc did not improve\n",
      "Epoch 312/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.3036 - acc: 0.9108 - val_loss: 0.2545 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00312: acc did not improve\n",
      "Epoch 313/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2997 - acc: 0.9108 - val_loss: 0.2546 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00313: acc did not improve\n",
      "Epoch 314/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.3023 - acc: 0.9077 - val_loss: 0.2560 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00314: acc did not improve\n",
      "Epoch 315/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.2968 - acc: 0.9154 - val_loss: 0.2530 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00315: acc did not improve\n",
      "Epoch 316/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2924 - acc: 0.9165 - val_loss: 0.2557 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00316: acc did not improve\n",
      "Epoch 317/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2961 - acc: 0.9165 - val_loss: 0.2598 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00317: acc did not improve\n",
      "Epoch 318/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.3023 - acc: 0.9134 - val_loss: 0.2539 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00318: acc did not improve\n",
      "Epoch 319/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2945 - acc: 0.9141 - val_loss: 0.2534 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00319: acc did not improve\n",
      "Epoch 320/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2995 - acc: 0.9064 - val_loss: 0.2500 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00320: acc did not improve\n",
      "Epoch 321/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2896 - acc: 0.9147 - val_loss: 0.2517 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00321: acc did not improve\n",
      "Epoch 322/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2923 - acc: 0.9169 - val_loss: 0.2512 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00322: acc improved from 0.91668 to 0.91690, saving model to best_model_FFW\n",
      "Epoch 323/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.2925 - acc: 0.9130 - val_loss: 0.2503 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00323: acc did not improve\n",
      "Epoch 324/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2923 - acc: 0.9154 - val_loss: 0.2490 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00324: acc did not improve\n",
      "Epoch 325/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2976 - acc: 0.9152 - val_loss: 0.2457 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00325: acc did not improve\n",
      "Epoch 326/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2987 - acc: 0.9138 - val_loss: 0.2448 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00326: acc did not improve\n",
      "Epoch 327/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2999 - acc: 0.9136 - val_loss: 0.2459 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00327: acc did not improve\n",
      "Epoch 328/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2999 - acc: 0.9099 - val_loss: 0.2443 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00328: acc did not improve\n",
      "Epoch 329/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.2951 - acc: 0.9136 - val_loss: 0.2449 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00329: acc did not improve\n",
      "Epoch 330/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2911 - acc: 0.9171 - val_loss: 0.2447 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00330: acc improved from 0.91690 to 0.91712, saving model to best_model_FFW\n",
      "Epoch 331/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2987 - acc: 0.9130 - val_loss: 0.2481 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00331: acc did not improve\n",
      "Epoch 332/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2885 - acc: 0.9173 - val_loss: 0.2507 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00332: acc improved from 0.91712 to 0.91734, saving model to best_model_FFW\n",
      "Epoch 333/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2929 - acc: 0.9090 - val_loss: 0.2493 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00333: acc did not improve\n",
      "Epoch 334/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2879 - acc: 0.9143 - val_loss: 0.2500 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00334: acc did not improve\n",
      "Epoch 335/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2867 - acc: 0.9141 - val_loss: 0.2490 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00335: acc did not improve\n",
      "Epoch 336/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2858 - acc: 0.9195 - val_loss: 0.2481 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00336: acc improved from 0.91734 to 0.91953, saving model to best_model_FFW\n",
      "Epoch 337/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2854 - acc: 0.9195 - val_loss: 0.2464 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00337: acc did not improve\n",
      "Epoch 338/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2868 - acc: 0.9121 - val_loss: 0.2464 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00338: acc did not improve\n",
      "Epoch 339/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2894 - acc: 0.9162 - val_loss: 0.2458 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00339: acc did not improve\n",
      "Epoch 340/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2862 - acc: 0.9149 - val_loss: 0.2466 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00340: acc did not improve\n",
      "Epoch 341/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2968 - acc: 0.9154 - val_loss: 0.2445 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00341: acc did not improve\n",
      "Epoch 342/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2829 - acc: 0.9171 - val_loss: 0.2436 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00342: acc did not improve\n",
      "Epoch 343/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2863 - acc: 0.9180 - val_loss: 0.2448 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00343: acc did not improve\n",
      "Epoch 344/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2912 - acc: 0.9136 - val_loss: 0.2462 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00344: acc did not improve\n",
      "Epoch 345/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2898 - acc: 0.9160 - val_loss: 0.2458 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00345: acc did not improve\n",
      "Epoch 346/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2841 - acc: 0.9176 - val_loss: 0.2439 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00346: acc did not improve\n",
      "Epoch 347/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2818 - acc: 0.9195 - val_loss: 0.2422 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00347: acc improved from 0.91953 to 0.91953, saving model to best_model_FFW\n",
      "Epoch 348/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2907 - acc: 0.9152 - val_loss: 0.2432 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00348: acc did not improve\n",
      "Epoch 349/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2858 - acc: 0.9171 - val_loss: 0.2455 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00349: acc did not improve\n",
      "Epoch 350/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2844 - acc: 0.9169 - val_loss: 0.2433 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00350: acc did not improve\n",
      "Epoch 351/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2864 - acc: 0.9195 - val_loss: 0.2402 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00351: acc improved from 0.91953 to 0.91953, saving model to best_model_FFW\n",
      "Epoch 352/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2795 - acc: 0.9184 - val_loss: 0.2427 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00352: acc did not improve\n",
      "Epoch 353/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2850 - acc: 0.9158 - val_loss: 0.2404 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00353: acc did not improve\n",
      "Epoch 354/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2827 - acc: 0.9189 - val_loss: 0.2422 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00354: acc did not improve\n",
      "Epoch 355/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2839 - acc: 0.9171 - val_loss: 0.2425 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00355: acc did not improve\n",
      "Epoch 356/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2895 - acc: 0.9143 - val_loss: 0.2414 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00356: acc did not improve\n",
      "Epoch 357/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2880 - acc: 0.9176 - val_loss: 0.2428 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00357: acc did not improve\n",
      "Epoch 358/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2834 - acc: 0.9202 - val_loss: 0.2398 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00358: acc improved from 0.91953 to 0.92018, saving model to best_model_FFW\n",
      "Epoch 359/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.2866 - acc: 0.9145 - val_loss: 0.2417 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00359: acc did not improve\n",
      "Epoch 360/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2841 - acc: 0.9206 - val_loss: 0.2378 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00360: acc improved from 0.92018 to 0.92062, saving model to best_model_FFW\n",
      "Epoch 361/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2843 - acc: 0.9193 - val_loss: 0.2380 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00361: acc did not improve\n",
      "Epoch 362/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2825 - acc: 0.9178 - val_loss: 0.2393 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00362: acc did not improve\n",
      "Epoch 363/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2836 - acc: 0.9182 - val_loss: 0.2393 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00363: acc did not improve\n",
      "Epoch 364/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.2791 - acc: 0.9187 - val_loss: 0.2372 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00364: acc did not improve\n",
      "Epoch 365/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2850 - acc: 0.9154 - val_loss: 0.2364 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00365: acc did not improve\n",
      "Epoch 366/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2823 - acc: 0.9193 - val_loss: 0.2395 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00366: acc did not improve\n",
      "Epoch 367/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2804 - acc: 0.9182 - val_loss: 0.2391 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00367: acc did not improve\n",
      "Epoch 368/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2768 - acc: 0.9195 - val_loss: 0.2381 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00368: acc did not improve\n",
      "Epoch 369/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2818 - acc: 0.9182 - val_loss: 0.2361 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00369: acc did not improve\n",
      "Epoch 370/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2851 - acc: 0.9215 - val_loss: 0.2375 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00370: acc improved from 0.92062 to 0.92150, saving model to best_model_FFW\n",
      "Epoch 371/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2775 - acc: 0.9232 - val_loss: 0.2403 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00371: acc improved from 0.92150 to 0.92325, saving model to best_model_FFW\n",
      "Epoch 372/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2874 - acc: 0.9158 - val_loss: 0.2355 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00372: acc did not improve\n",
      "Epoch 373/600\n",
      "4573/4573 [==============================] - 0s 24us/step - loss: 0.2771 - acc: 0.9162 - val_loss: 0.2384 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00373: acc did not improve\n",
      "Epoch 374/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2815 - acc: 0.9222 - val_loss: 0.2349 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00374: acc did not improve\n",
      "Epoch 375/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2802 - acc: 0.9160 - val_loss: 0.2344 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00375: acc did not improve\n",
      "Epoch 376/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2766 - acc: 0.9193 - val_loss: 0.2381 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00376: acc did not improve\n",
      "Epoch 377/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2797 - acc: 0.9204 - val_loss: 0.2371 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00377: acc did not improve\n",
      "Epoch 378/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2800 - acc: 0.9191 - val_loss: 0.2351 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00378: acc did not improve\n",
      "Epoch 379/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2803 - acc: 0.9189 - val_loss: 0.2331 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00379: acc did not improve\n",
      "Epoch 380/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2820 - acc: 0.9222 - val_loss: 0.2336 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00380: acc did not improve\n",
      "Epoch 381/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2814 - acc: 0.9197 - val_loss: 0.2326 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00381: acc did not improve\n",
      "Epoch 382/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2796 - acc: 0.9193 - val_loss: 0.2333 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00382: acc did not improve\n",
      "Epoch 383/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2739 - acc: 0.9235 - val_loss: 0.2344 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00383: acc improved from 0.92325 to 0.92346, saving model to best_model_FFW\n",
      "Epoch 384/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2750 - acc: 0.9224 - val_loss: 0.2344 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00384: acc did not improve\n",
      "Epoch 385/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2792 - acc: 0.9204 - val_loss: 0.2339 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00385: acc did not improve\n",
      "Epoch 386/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2780 - acc: 0.9217 - val_loss: 0.2358 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00386: acc did not improve\n",
      "Epoch 387/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2756 - acc: 0.9241 - val_loss: 0.2292 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00387: acc improved from 0.92346 to 0.92412, saving model to best_model_FFW\n",
      "Epoch 388/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2783 - acc: 0.9182 - val_loss: 0.2354 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00388: acc did not improve\n",
      "Epoch 389/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2837 - acc: 0.9200 - val_loss: 0.2340 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00389: acc did not improve\n",
      "Epoch 390/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2775 - acc: 0.9215 - val_loss: 0.2324 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00390: acc did not improve\n",
      "Epoch 391/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2782 - acc: 0.9197 - val_loss: 0.2326 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00391: acc did not improve\n",
      "Epoch 392/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2722 - acc: 0.9230 - val_loss: 0.2316 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00392: acc did not improve\n",
      "Epoch 393/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2781 - acc: 0.9204 - val_loss: 0.2323 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00393: acc did not improve\n",
      "Epoch 394/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2753 - acc: 0.9184 - val_loss: 0.2302 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00394: acc did not improve\n",
      "Epoch 395/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2727 - acc: 0.9222 - val_loss: 0.2346 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00395: acc did not improve\n",
      "Epoch 396/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2758 - acc: 0.9178 - val_loss: 0.2320 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00396: acc did not improve\n",
      "Epoch 397/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2731 - acc: 0.9206 - val_loss: 0.2347 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00397: acc did not improve\n",
      "Epoch 398/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2807 - acc: 0.9193 - val_loss: 0.2321 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00398: acc did not improve\n",
      "Epoch 399/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2722 - acc: 0.9226 - val_loss: 0.2298 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00399: acc did not improve\n",
      "Epoch 400/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2746 - acc: 0.9224 - val_loss: 0.2266 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00400: acc did not improve\n",
      "Epoch 401/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2771 - acc: 0.9202 - val_loss: 0.2276 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00401: acc did not improve\n",
      "Epoch 402/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2776 - acc: 0.9213 - val_loss: 0.2271 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00402: acc did not improve\n",
      "Epoch 403/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2750 - acc: 0.9208 - val_loss: 0.2307 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00403: acc did not improve\n",
      "Epoch 404/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2746 - acc: 0.9187 - val_loss: 0.2306 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00404: acc did not improve\n",
      "Epoch 405/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2733 - acc: 0.9224 - val_loss: 0.2301 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00405: acc did not improve\n",
      "Epoch 406/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2718 - acc: 0.9246 - val_loss: 0.2298 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00406: acc improved from 0.92412 to 0.92456, saving model to best_model_FFW\n",
      "Epoch 407/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2684 - acc: 0.9230 - val_loss: 0.2291 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00407: acc did not improve\n",
      "Epoch 408/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2676 - acc: 0.9254 - val_loss: 0.2298 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00408: acc improved from 0.92456 to 0.92543, saving model to best_model_FFW\n",
      "Epoch 409/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2797 - acc: 0.9224 - val_loss: 0.2309 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00409: acc did not improve\n",
      "Epoch 410/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2717 - acc: 0.9211 - val_loss: 0.2278 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00410: acc did not improve\n",
      "Epoch 411/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2684 - acc: 0.9222 - val_loss: 0.2322 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00411: acc did not improve\n",
      "Epoch 412/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2756 - acc: 0.9237 - val_loss: 0.2293 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00412: acc did not improve\n",
      "Epoch 413/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2742 - acc: 0.9224 - val_loss: 0.2308 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00413: acc did not improve\n",
      "Epoch 414/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2716 - acc: 0.9239 - val_loss: 0.2277 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00414: acc did not improve\n",
      "Epoch 415/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2749 - acc: 0.9193 - val_loss: 0.2266 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00415: acc did not improve\n",
      "Epoch 416/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2704 - acc: 0.9202 - val_loss: 0.2264 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00416: acc did not improve\n",
      "Epoch 417/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2632 - acc: 0.9261 - val_loss: 0.2254 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00417: acc improved from 0.92543 to 0.92609, saving model to best_model_FFW\n",
      "Epoch 418/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2673 - acc: 0.9230 - val_loss: 0.2252 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00418: acc did not improve\n",
      "Epoch 419/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2688 - acc: 0.9237 - val_loss: 0.2241 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00419: acc did not improve\n",
      "Epoch 420/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2711 - acc: 0.9281 - val_loss: 0.2260 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00420: acc improved from 0.92609 to 0.92806, saving model to best_model_FFW\n",
      "Epoch 421/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2703 - acc: 0.9254 - val_loss: 0.2302 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00421: acc did not improve\n",
      "Epoch 422/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2670 - acc: 0.9246 - val_loss: 0.2326 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00422: acc did not improve\n",
      "Epoch 423/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2721 - acc: 0.9239 - val_loss: 0.2316 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00423: acc did not improve\n",
      "Epoch 424/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2694 - acc: 0.9230 - val_loss: 0.2265 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00424: acc did not improve\n",
      "Epoch 425/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2671 - acc: 0.9235 - val_loss: 0.2263 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00425: acc did not improve\n",
      "Epoch 426/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2674 - acc: 0.9257 - val_loss: 0.2225 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00426: acc did not improve\n",
      "Epoch 427/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2734 - acc: 0.9208 - val_loss: 0.2250 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00427: acc did not improve\n",
      "Epoch 428/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2693 - acc: 0.9254 - val_loss: 0.2258 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00428: acc did not improve\n",
      "Epoch 429/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2637 - acc: 0.9248 - val_loss: 0.2241 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00429: acc did not improve\n",
      "Epoch 430/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2763 - acc: 0.9215 - val_loss: 0.2264 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00430: acc did not improve\n",
      "Epoch 431/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2659 - acc: 0.9259 - val_loss: 0.2248 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00431: acc did not improve\n",
      "Epoch 432/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2652 - acc: 0.9254 - val_loss: 0.2250 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00432: acc did not improve\n",
      "Epoch 433/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2670 - acc: 0.9237 - val_loss: 0.2242 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00433: acc did not improve\n",
      "Epoch 434/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2739 - acc: 0.9206 - val_loss: 0.2234 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00434: acc did not improve\n",
      "Epoch 435/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2729 - acc: 0.9230 - val_loss: 0.2249 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00435: acc did not improve\n",
      "Epoch 436/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2693 - acc: 0.9261 - val_loss: 0.2228 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00436: acc did not improve\n",
      "Epoch 437/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2695 - acc: 0.9224 - val_loss: 0.2235 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00437: acc did not improve\n",
      "Epoch 438/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2677 - acc: 0.9228 - val_loss: 0.2217 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00438: acc did not improve\n",
      "Epoch 439/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2649 - acc: 0.9250 - val_loss: 0.2222 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00439: acc did not improve\n",
      "Epoch 440/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2626 - acc: 0.9287 - val_loss: 0.2223 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00440: acc improved from 0.92806 to 0.92871, saving model to best_model_FFW\n",
      "Epoch 441/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2637 - acc: 0.9254 - val_loss: 0.2250 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00441: acc did not improve\n",
      "Epoch 442/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2640 - acc: 0.9259 - val_loss: 0.2243 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00442: acc did not improve\n",
      "Epoch 443/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2674 - acc: 0.9250 - val_loss: 0.2200 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00443: acc did not improve\n",
      "Epoch 444/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2609 - acc: 0.9270 - val_loss: 0.2197 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00444: acc did not improve\n",
      "Epoch 445/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2689 - acc: 0.9252 - val_loss: 0.2202 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00445: acc did not improve\n",
      "Epoch 446/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2686 - acc: 0.9226 - val_loss: 0.2210 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00446: acc did not improve\n",
      "Epoch 447/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2588 - acc: 0.9252 - val_loss: 0.2230 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00447: acc did not improve\n",
      "Epoch 448/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2651 - acc: 0.9246 - val_loss: 0.2250 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00448: acc did not improve\n",
      "Epoch 449/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2660 - acc: 0.9243 - val_loss: 0.2233 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00449: acc did not improve\n",
      "Epoch 450/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2690 - acc: 0.9213 - val_loss: 0.2208 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00450: acc did not improve\n",
      "Epoch 451/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2640 - acc: 0.9291 - val_loss: 0.2210 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00451: acc improved from 0.92871 to 0.92915, saving model to best_model_FFW\n",
      "Epoch 452/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2613 - acc: 0.9259 - val_loss: 0.2237 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00452: acc did not improve\n",
      "Epoch 453/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2704 - acc: 0.9235 - val_loss: 0.2215 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00453: acc did not improve\n",
      "Epoch 454/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2646 - acc: 0.9224 - val_loss: 0.2228 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00454: acc did not improve\n",
      "Epoch 455/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2564 - acc: 0.9281 - val_loss: 0.2205 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00455: acc did not improve\n",
      "Epoch 456/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2631 - acc: 0.9278 - val_loss: 0.2224 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00456: acc did not improve\n",
      "Epoch 457/600\n",
      "4573/4573 [==============================] - 0s 37us/step - loss: 0.2564 - acc: 0.9257 - val_loss: 0.2217 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00457: acc did not improve\n",
      "Epoch 458/600\n",
      "4573/4573 [==============================] - 0s 40us/step - loss: 0.2642 - acc: 0.9230 - val_loss: 0.2223 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00458: acc did not improve\n",
      "Epoch 459/600\n",
      "4573/4573 [==============================] - 0s 37us/step - loss: 0.2675 - acc: 0.9267 - val_loss: 0.2206 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00459: acc did not improve\n",
      "Epoch 460/600\n",
      "4573/4573 [==============================] - 0s 38us/step - loss: 0.2655 - acc: 0.9235 - val_loss: 0.2200 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00460: acc did not improve\n",
      "Epoch 461/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2600 - acc: 0.9270 - val_loss: 0.2199 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00461: acc did not improve\n",
      "Epoch 462/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2634 - acc: 0.9283 - val_loss: 0.2207 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00462: acc did not improve\n",
      "Epoch 463/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2653 - acc: 0.9241 - val_loss: 0.2180 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00463: acc did not improve\n",
      "Epoch 464/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2628 - acc: 0.9265 - val_loss: 0.2192 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00464: acc did not improve\n",
      "Epoch 465/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2619 - acc: 0.9263 - val_loss: 0.2179 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00465: acc did not improve\n",
      "Epoch 466/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.2674 - acc: 0.9257 - val_loss: 0.2202 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00466: acc did not improve\n",
      "Epoch 467/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2600 - acc: 0.9257 - val_loss: 0.2192 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00467: acc did not improve\n",
      "Epoch 468/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2630 - acc: 0.9254 - val_loss: 0.2187 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00468: acc did not improve\n",
      "Epoch 469/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2645 - acc: 0.9252 - val_loss: 0.2171 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00469: acc did not improve\n",
      "Epoch 470/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2611 - acc: 0.9291 - val_loss: 0.2169 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00470: acc did not improve\n",
      "Epoch 471/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2591 - acc: 0.9230 - val_loss: 0.2166 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00471: acc did not improve\n",
      "Epoch 472/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2587 - acc: 0.9331 - val_loss: 0.2174 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00472: acc improved from 0.92915 to 0.93309, saving model to best_model_FFW\n",
      "Epoch 473/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2652 - acc: 0.9272 - val_loss: 0.2186 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00473: acc did not improve\n",
      "Epoch 474/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2598 - acc: 0.9274 - val_loss: 0.2173 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00474: acc did not improve\n",
      "Epoch 475/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2624 - acc: 0.9237 - val_loss: 0.2179 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00475: acc did not improve\n",
      "Epoch 476/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2608 - acc: 0.9261 - val_loss: 0.2186 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00476: acc did not improve\n",
      "Epoch 477/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2669 - acc: 0.9232 - val_loss: 0.2152 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00477: acc did not improve\n",
      "Epoch 478/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2600 - acc: 0.9276 - val_loss: 0.2155 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00478: acc did not improve\n",
      "Epoch 479/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2583 - acc: 0.9254 - val_loss: 0.2162 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00479: acc did not improve\n",
      "Epoch 480/600\n",
      "4573/4573 [==============================] - 0s 36us/step - loss: 0.2604 - acc: 0.9252 - val_loss: 0.2171 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00480: acc did not improve\n",
      "Epoch 481/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2535 - acc: 0.9294 - val_loss: 0.2170 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00481: acc did not improve\n",
      "Epoch 482/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2623 - acc: 0.9278 - val_loss: 0.2168 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00482: acc did not improve\n",
      "Epoch 483/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2517 - acc: 0.9274 - val_loss: 0.2181 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00483: acc did not improve\n",
      "Epoch 484/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2552 - acc: 0.9252 - val_loss: 0.2166 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00484: acc did not improve\n",
      "Epoch 485/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2622 - acc: 0.9200 - val_loss: 0.2149 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00485: acc did not improve\n",
      "Epoch 486/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2584 - acc: 0.9237 - val_loss: 0.2181 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00486: acc did not improve\n",
      "Epoch 487/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2602 - acc: 0.9235 - val_loss: 0.2157 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00487: acc did not improve\n",
      "Epoch 488/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2623 - acc: 0.9239 - val_loss: 0.2187 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00488: acc did not improve\n",
      "Epoch 489/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2601 - acc: 0.9257 - val_loss: 0.2175 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00489: acc did not improve\n",
      "Epoch 490/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2590 - acc: 0.9265 - val_loss: 0.2177 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00490: acc did not improve\n",
      "Epoch 491/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2593 - acc: 0.9267 - val_loss: 0.2163 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00491: acc did not improve\n",
      "Epoch 492/600\n",
      "4573/4573 [==============================] - 0s 37us/step - loss: 0.2552 - acc: 0.9237 - val_loss: 0.2157 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00492: acc did not improve\n",
      "Epoch 493/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2570 - acc: 0.9281 - val_loss: 0.2159 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00493: acc did not improve\n",
      "Epoch 494/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2572 - acc: 0.9302 - val_loss: 0.2159 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00494: acc did not improve\n",
      "Epoch 495/600\n",
      "4573/4573 [==============================] - 0s 37us/step - loss: 0.2616 - acc: 0.9300 - val_loss: 0.2144 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00495: acc did not improve\n",
      "Epoch 496/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2644 - acc: 0.9243 - val_loss: 0.2143 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00496: acc did not improve\n",
      "Epoch 497/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2652 - acc: 0.9237 - val_loss: 0.2146 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00497: acc did not improve\n",
      "Epoch 498/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2650 - acc: 0.9243 - val_loss: 0.2148 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00498: acc did not improve\n",
      "Epoch 499/600\n",
      "4573/4573 [==============================] - 0s 37us/step - loss: 0.2597 - acc: 0.9265 - val_loss: 0.2139 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00499: acc did not improve\n",
      "Epoch 500/600\n",
      "4573/4573 [==============================] - 0s 37us/step - loss: 0.2572 - acc: 0.9259 - val_loss: 0.2132 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00500: acc did not improve\n",
      "Epoch 501/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2547 - acc: 0.9267 - val_loss: 0.2147 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00501: acc did not improve\n",
      "Epoch 502/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2567 - acc: 0.9265 - val_loss: 0.2122 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00502: acc did not improve\n",
      "Epoch 503/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2582 - acc: 0.9285 - val_loss: 0.2130 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00503: acc did not improve\n",
      "Epoch 504/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2592 - acc: 0.9265 - val_loss: 0.2131 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00504: acc did not improve\n",
      "Epoch 505/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2571 - acc: 0.9276 - val_loss: 0.2137 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00505: acc did not improve\n",
      "Epoch 506/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2616 - acc: 0.9230 - val_loss: 0.2148 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00506: acc did not improve\n",
      "Epoch 507/600\n",
      "4573/4573 [==============================] - 0s 38us/step - loss: 0.2494 - acc: 0.9281 - val_loss: 0.2165 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00507: acc did not improve\n",
      "Epoch 508/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2607 - acc: 0.9291 - val_loss: 0.2155 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00508: acc did not improve\n",
      "Epoch 509/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2516 - acc: 0.9296 - val_loss: 0.2117 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00509: acc did not improve\n",
      "Epoch 510/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2589 - acc: 0.9267 - val_loss: 0.2102 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00510: acc did not improve\n",
      "Epoch 511/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2525 - acc: 0.9261 - val_loss: 0.2142 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00511: acc did not improve\n",
      "Epoch 512/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2597 - acc: 0.9246 - val_loss: 0.2100 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00512: acc did not improve\n",
      "Epoch 513/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2507 - acc: 0.9278 - val_loss: 0.2119 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00513: acc did not improve\n",
      "Epoch 514/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2588 - acc: 0.9261 - val_loss: 0.2125 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00514: acc did not improve\n",
      "Epoch 515/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2556 - acc: 0.9274 - val_loss: 0.2115 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00515: acc did not improve\n",
      "Epoch 516/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2577 - acc: 0.9291 - val_loss: 0.2127 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00516: acc did not improve\n",
      "Epoch 517/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2561 - acc: 0.9261 - val_loss: 0.2121 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00517: acc did not improve\n",
      "Epoch 518/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2604 - acc: 0.9291 - val_loss: 0.2121 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00518: acc did not improve\n",
      "Epoch 519/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2574 - acc: 0.9305 - val_loss: 0.2107 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00519: acc did not improve\n",
      "Epoch 520/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2502 - acc: 0.9283 - val_loss: 0.2134 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00520: acc did not improve\n",
      "Epoch 521/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2546 - acc: 0.9294 - val_loss: 0.2104 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00521: acc did not improve\n",
      "Epoch 522/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2597 - acc: 0.9267 - val_loss: 0.2121 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00522: acc did not improve\n",
      "Epoch 523/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2567 - acc: 0.9291 - val_loss: 0.2117 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00523: acc did not improve\n",
      "Epoch 524/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2522 - acc: 0.9285 - val_loss: 0.2112 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00524: acc did not improve\n",
      "Epoch 525/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2473 - acc: 0.9289 - val_loss: 0.2113 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00525: acc did not improve\n",
      "Epoch 526/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2568 - acc: 0.9267 - val_loss: 0.2120 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00526: acc did not improve\n",
      "Epoch 527/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2506 - acc: 0.9270 - val_loss: 0.2103 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00527: acc did not improve\n",
      "Epoch 528/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2511 - acc: 0.9309 - val_loss: 0.2121 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00528: acc did not improve\n",
      "Epoch 529/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2490 - acc: 0.9316 - val_loss: 0.2094 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00529: acc did not improve\n",
      "Epoch 530/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2507 - acc: 0.9296 - val_loss: 0.2103 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00530: acc did not improve\n",
      "Epoch 531/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2508 - acc: 0.9267 - val_loss: 0.2114 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00531: acc did not improve\n",
      "Epoch 532/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.2534 - acc: 0.9246 - val_loss: 0.2115 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00532: acc did not improve\n",
      "Epoch 533/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2559 - acc: 0.9311 - val_loss: 0.2124 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00533: acc did not improve\n",
      "Epoch 534/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2574 - acc: 0.9254 - val_loss: 0.2111 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00534: acc did not improve\n",
      "Epoch 535/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2511 - acc: 0.9311 - val_loss: 0.2100 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00535: acc did not improve\n",
      "Epoch 536/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2502 - acc: 0.9296 - val_loss: 0.2082 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00536: acc did not improve\n",
      "Epoch 537/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2462 - acc: 0.9305 - val_loss: 0.2089 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00537: acc did not improve\n",
      "Epoch 538/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2503 - acc: 0.9252 - val_loss: 0.2102 - val_acc: 0.9411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00538: acc did not improve\n",
      "Epoch 539/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2533 - acc: 0.9270 - val_loss: 0.2130 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00539: acc did not improve\n",
      "Epoch 540/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2572 - acc: 0.9257 - val_loss: 0.2114 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00540: acc did not improve\n",
      "Epoch 541/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2498 - acc: 0.9287 - val_loss: 0.2104 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00541: acc did not improve\n",
      "Epoch 542/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2493 - acc: 0.9305 - val_loss: 0.2097 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00542: acc did not improve\n",
      "Epoch 543/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2516 - acc: 0.9309 - val_loss: 0.2109 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00543: acc did not improve\n",
      "Epoch 544/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2535 - acc: 0.9298 - val_loss: 0.2080 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00544: acc did not improve\n",
      "Epoch 545/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2521 - acc: 0.9289 - val_loss: 0.2082 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00545: acc did not improve\n",
      "Epoch 546/600\n",
      "4573/4573 [==============================] - 0s 32us/step - loss: 0.2476 - acc: 0.9278 - val_loss: 0.2089 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00546: acc did not improve\n",
      "Epoch 547/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2493 - acc: 0.9309 - val_loss: 0.2100 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00547: acc did not improve\n",
      "Epoch 548/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.2549 - acc: 0.9276 - val_loss: 0.2091 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00548: acc did not improve\n",
      "Epoch 549/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2466 - acc: 0.9313 - val_loss: 0.2095 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00549: acc did not improve\n",
      "Epoch 550/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2535 - acc: 0.9261 - val_loss: 0.2079 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00550: acc did not improve\n",
      "Epoch 551/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2528 - acc: 0.9298 - val_loss: 0.2082 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00551: acc did not improve\n",
      "Epoch 552/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2456 - acc: 0.9287 - val_loss: 0.2082 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00552: acc did not improve\n",
      "Epoch 553/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2466 - acc: 0.9300 - val_loss: 0.2094 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00553: acc did not improve\n",
      "Epoch 554/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2480 - acc: 0.9294 - val_loss: 0.2117 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00554: acc did not improve\n",
      "Epoch 555/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2527 - acc: 0.9305 - val_loss: 0.2102 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00555: acc did not improve\n",
      "Epoch 556/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2495 - acc: 0.9289 - val_loss: 0.2106 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00556: acc did not improve\n",
      "Epoch 557/600\n",
      "4573/4573 [==============================] - 0s 38us/step - loss: 0.2477 - acc: 0.9287 - val_loss: 0.2081 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00557: acc did not improve\n",
      "Epoch 558/600\n",
      "4573/4573 [==============================] - 0s 37us/step - loss: 0.2414 - acc: 0.9318 - val_loss: 0.2105 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00558: acc did not improve\n",
      "Epoch 559/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2453 - acc: 0.9313 - val_loss: 0.2087 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00559: acc did not improve\n",
      "Epoch 560/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2498 - acc: 0.9320 - val_loss: 0.2069 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00560: acc did not improve\n",
      "Epoch 561/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2442 - acc: 0.9333 - val_loss: 0.2086 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00561: acc improved from 0.93309 to 0.93330, saving model to best_model_FFW\n",
      "Epoch 562/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2505 - acc: 0.9302 - val_loss: 0.2057 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00562: acc did not improve\n",
      "Epoch 563/600\n",
      "4573/4573 [==============================] - 0s 28us/step - loss: 0.2478 - acc: 0.9283 - val_loss: 0.2072 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00563: acc did not improve\n",
      "Epoch 564/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2464 - acc: 0.9313 - val_loss: 0.2088 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00564: acc did not improve\n",
      "Epoch 565/600\n",
      "4573/4573 [==============================] - 0s 36us/step - loss: 0.2487 - acc: 0.9302 - val_loss: 0.2077 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00565: acc did not improve\n",
      "Epoch 566/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2457 - acc: 0.9270 - val_loss: 0.2083 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00566: acc did not improve\n",
      "Epoch 567/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2486 - acc: 0.9294 - val_loss: 0.2076 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00567: acc did not improve\n",
      "Epoch 568/600\n",
      "4573/4573 [==============================] - 0s 29us/step - loss: 0.2473 - acc: 0.9296 - val_loss: 0.2083 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00568: acc did not improve\n",
      "Epoch 569/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2456 - acc: 0.9313 - val_loss: 0.2094 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00569: acc did not improve\n",
      "Epoch 570/600\n",
      "4573/4573 [==============================] - 0s 37us/step - loss: 0.2513 - acc: 0.9281 - val_loss: 0.2089 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00570: acc did not improve\n",
      "Epoch 571/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2447 - acc: 0.9305 - val_loss: 0.2070 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00571: acc did not improve\n",
      "Epoch 572/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2477 - acc: 0.9309 - val_loss: 0.2083 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00572: acc did not improve\n",
      "Epoch 573/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2502 - acc: 0.9274 - val_loss: 0.2065 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00573: acc did not improve\n",
      "Epoch 574/600\n",
      "4573/4573 [==============================] - 0s 36us/step - loss: 0.2482 - acc: 0.9283 - val_loss: 0.2060 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00574: acc did not improve\n",
      "Epoch 575/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2438 - acc: 0.9300 - val_loss: 0.2088 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00575: acc did not improve\n",
      "Epoch 576/600\n",
      "4573/4573 [==============================] - 0s 36us/step - loss: 0.2470 - acc: 0.9298 - val_loss: 0.2075 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00576: acc did not improve\n",
      "Epoch 577/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2491 - acc: 0.9267 - val_loss: 0.2059 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00577: acc did not improve\n",
      "Epoch 578/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2471 - acc: 0.9300 - val_loss: 0.2047 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00578: acc did not improve\n",
      "Epoch 579/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2421 - acc: 0.9305 - val_loss: 0.2079 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00579: acc did not improve\n",
      "Epoch 580/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2473 - acc: 0.9309 - val_loss: 0.2067 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00580: acc did not improve\n",
      "Epoch 581/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2581 - acc: 0.9276 - val_loss: 0.2060 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00581: acc did not improve\n",
      "Epoch 582/600\n",
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2521 - acc: 0.9272 - val_loss: 0.2045 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00582: acc did not improve\n",
      "Epoch 583/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2372 - acc: 0.9337 - val_loss: 0.2059 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00583: acc improved from 0.93330 to 0.93374, saving model to best_model_FFW\n",
      "Epoch 584/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2501 - acc: 0.9305 - val_loss: 0.2063 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00584: acc did not improve\n",
      "Epoch 585/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2412 - acc: 0.9331 - val_loss: 0.2064 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00585: acc did not improve\n",
      "Epoch 586/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 33us/step - loss: 0.2543 - acc: 0.9281 - val_loss: 0.2064 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00586: acc did not improve\n",
      "Epoch 587/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2461 - acc: 0.9307 - val_loss: 0.2058 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00587: acc did not improve\n",
      "Epoch 588/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2456 - acc: 0.9270 - val_loss: 0.2053 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00588: acc did not improve\n",
      "Epoch 589/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2462 - acc: 0.9278 - val_loss: 0.2060 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00589: acc did not improve\n",
      "Epoch 590/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2500 - acc: 0.9285 - val_loss: 0.2050 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00590: acc did not improve\n",
      "Epoch 591/600\n",
      "4573/4573 [==============================] - 0s 26us/step - loss: 0.2426 - acc: 0.9307 - val_loss: 0.2050 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00591: acc did not improve\n",
      "Epoch 592/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2489 - acc: 0.9291 - val_loss: 0.2059 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00592: acc did not improve\n",
      "Epoch 593/600\n",
      "4573/4573 [==============================] - 0s 30us/step - loss: 0.2499 - acc: 0.9291 - val_loss: 0.2040 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00593: acc did not improve\n",
      "Epoch 594/600\n",
      "4573/4573 [==============================] - 0s 31us/step - loss: 0.2538 - acc: 0.9302 - val_loss: 0.2039 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00594: acc did not improve\n",
      "Epoch 595/600\n",
      "4573/4573 [==============================] - 0s 25us/step - loss: 0.2419 - acc: 0.9335 - val_loss: 0.2056 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00595: acc did not improve\n",
      "Epoch 596/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2457 - acc: 0.9318 - val_loss: 0.2053 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00596: acc did not improve\n",
      "Epoch 597/600\n",
      "4573/4573 [==============================] - 0s 27us/step - loss: 0.2504 - acc: 0.9344 - val_loss: 0.2047 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00597: acc improved from 0.93374 to 0.93440, saving model to best_model_FFW\n",
      "Epoch 598/600\n",
      "4573/4573 [==============================] - 0s 35us/step - loss: 0.2477 - acc: 0.9285 - val_loss: 0.2050 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00598: acc did not improve\n",
      "Epoch 599/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2477 - acc: 0.9320 - val_loss: 0.2049 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00599: acc did not improve\n",
      "Epoch 600/600\n",
      "4573/4573 [==============================] - 0s 34us/step - loss: 0.2466 - acc: 0.9318 - val_loss: 0.2068 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00600: acc did not improve\n"
     ]
    }
   ],
   "source": [
    "FFW = Sequential()\n",
    "\n",
    "FFW.add(Dense(30, input_shape=(len(X_train[0]),)))\n",
    "FFW.add(Activation('relu'))\n",
    "\n",
    "FFW.add(Dense(18))\n",
    "FFW.add(BatchNormalization(axis=1))\n",
    "FFW.add(Dropout(0.7))\n",
    "FFW.add(Activation('relu'))\n",
    "\n",
    "FFW.add(Dense(1))\n",
    "FFW.add(BatchNormalization(axis=1))\n",
    "FFW.add(Activation('sigmoid'))\n",
    "\n",
    "FFW.summary()\n",
    "\n",
    "FFW.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "save_model_path = 'best_model_FFW'\n",
    "earlystopping = EarlyStopping(monitor = 'val_acc', patience=10)\n",
    "modelcheckpoint = ModelCheckpoint(save_model_path, monitor = 'acc', verbose = 1, save_best_only = True)\n",
    "\n",
    "history_FFW = FFW.fit(X_train, Y_train, batch_size=128, epochs = 600, validation_split = 0.1, callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6486/6486 [==============================] - 0s 66us/step\n",
      "0.8959296947638635\n"
     ]
    }
   ],
   "source": [
    "FFW = load_model(save_model_path)\n",
    "accuracy = FFW.evaluate(X_test, Y_test)[1]\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = getDataset(TRAIN_DATA_PATH, DEFAULT_FEATURES, flatten=False)\n",
    "X_test, Y_test = getDataset(TEST_DATA_PATH, DEFAULT_FEATURES, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6486/6486 [==============================] - 2s 342us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total']0.8928461301631851\n",
      "6486/6486 [==============================] - 2s 378us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total', 'baro_relative_altitude']0.8942337342886288\n",
      "6486/6486 [==============================] - 2s 384us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy']0.8595436324758585\n",
      "6486/6486 [==============================] - 3s 403us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed']0.8715695343633658\n",
      "6486/6486 [==============================] - 3s 432us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength']0.8618563058712289\n",
      "6486/6486 [==============================] - 3s 483us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total']0.8945420907486966\n",
      "6486/6486 [==============================] - 3s 496us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'baro_relative_altitude']0.8718778907682952\n",
      "6486/6486 [==============================] - 3s 499us/step\n",
      "['gps_vertical_accuracy', 'gps_horizontal_accuracy', 'gps_speed', 'rssi_strength', 'magnet_total', 'baro_pressure']0.8629355535917432\n"
     ]
    }
   ],
   "source": [
    "for features in features_list:\n",
    "    X_train, Y_train = getDataset(TRAIN_DATA_PATH, features,flatten=False)\n",
    "    X_test, Y_test = getDataset(TEST_DATA_PATH, features,flatten=False)\n",
    "    ltsm = Sequential()\n",
    "    ltsm.add(LSTM(128, input_shape=(3, len(X_train[0][0])), return_sequences=True,\n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "    ltsm.add(LSTM(2))\n",
    "    ltsm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    ltsm.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(0.006),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    save_model_path = 'best_model_LSTM'\n",
    "    modelcheckpoint = ModelCheckpoint(save_model_path, monitor = 'acc', verbose = 0, save_best_only = True)\n",
    "    history_lstm = ltsm.fit(X_train, Y_train, batch_size=128, epochs = 600, validation_split = 0.1, callbacks=[modelcheckpoint],verbose=0)\n",
    "    ltsm = load_model(save_model_path)\n",
    "    accuracy = ltsm.evaluate(X_test, Y_test)[1]\n",
    "    print str(features) + str(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 3, 128)            68608     \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 2)                 1048      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 69,659\n",
      "Trainable params: 69,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4573 samples, validate on 509 samples\n",
      "Epoch 1/600\n",
      "4573/4573 [==============================] - 8s 2ms/step - loss: 0.6399 - acc: 0.6350 - val_loss: 0.5958 - val_acc: 0.6916\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.63503, saving model to best_model_LSTM\n",
      "Epoch 2/600\n",
      "4573/4573 [==============================] - 0s 84us/step - loss: 0.5684 - acc: 0.7407 - val_loss: 0.5403 - val_acc: 0.7839\n",
      "\n",
      "Epoch 00002: acc improved from 0.63503 to 0.74065, saving model to best_model_LSTM\n",
      "Epoch 3/600\n",
      "4573/4573 [==============================] - 0s 85us/step - loss: 0.4914 - acc: 0.8185 - val_loss: 0.4403 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00003: acc improved from 0.74065 to 0.81850, saving model to best_model_LSTM\n",
      "Epoch 4/600\n",
      "4573/4573 [==============================] - 0s 85us/step - loss: 0.4098 - acc: 0.8758 - val_loss: 0.3310 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00004: acc improved from 0.81850 to 0.87579, saving model to best_model_LSTM\n",
      "Epoch 5/600\n",
      "4573/4573 [==============================] - 0s 85us/step - loss: 0.3404 - acc: 0.9108 - val_loss: 0.2772 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00005: acc improved from 0.87579 to 0.91078, saving model to best_model_LSTM\n",
      "Epoch 6/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.3178 - acc: 0.9136 - val_loss: 0.2638 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00006: acc improved from 0.91078 to 0.91362, saving model to best_model_LSTM\n",
      "Epoch 7/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.3094 - acc: 0.9114 - val_loss: 0.2636 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00007: acc did not improve\n",
      "Epoch 8/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2906 - acc: 0.9180 - val_loss: 0.3390 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00008: acc improved from 0.91362 to 0.91800, saving model to best_model_LSTM\n",
      "Epoch 9/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2924 - acc: 0.9092 - val_loss: 0.2618 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00009: acc did not improve\n",
      "Epoch 10/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2721 - acc: 0.9189 - val_loss: 0.2293 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00010: acc improved from 0.91800 to 0.91887, saving model to best_model_LSTM\n",
      "Epoch 11/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2723 - acc: 0.9202 - val_loss: 0.2471 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00011: acc improved from 0.91887 to 0.92018, saving model to best_model_LSTM\n",
      "Epoch 12/600\n",
      "4573/4573 [==============================] - 0s 93us/step - loss: 0.2677 - acc: 0.9178 - val_loss: 0.2316 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00012: acc did not improve\n",
      "Epoch 13/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2660 - acc: 0.9226 - val_loss: 0.2162 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00013: acc improved from 0.92018 to 0.92259, saving model to best_model_LSTM\n",
      "Epoch 14/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2710 - acc: 0.9180 - val_loss: 0.2211 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00014: acc did not improve\n",
      "Epoch 15/600\n",
      "4573/4573 [==============================] - 0s 85us/step - loss: 0.2549 - acc: 0.9265 - val_loss: 0.2133 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00015: acc improved from 0.92259 to 0.92653, saving model to best_model_LSTM\n",
      "Epoch 16/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2678 - acc: 0.9200 - val_loss: 0.2127 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00016: acc did not improve\n",
      "Epoch 17/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2728 - acc: 0.9169 - val_loss: 0.2135 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00017: acc did not improve\n",
      "Epoch 18/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2636 - acc: 0.9202 - val_loss: 0.2104 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00018: acc did not improve\n",
      "Epoch 19/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2600 - acc: 0.9224 - val_loss: 0.2261 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00019: acc did not improve\n",
      "Epoch 20/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2663 - acc: 0.9173 - val_loss: 0.2491 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00020: acc did not improve\n",
      "Epoch 21/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2589 - acc: 0.9235 - val_loss: 0.2219 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00021: acc did not improve\n",
      "Epoch 22/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2544 - acc: 0.9224 - val_loss: 0.2412 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00022: acc did not improve\n",
      "Epoch 23/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2578 - acc: 0.9235 - val_loss: 0.2191 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00023: acc did not improve\n",
      "Epoch 24/600\n",
      "4573/4573 [==============================] - 0s 93us/step - loss: 0.2902 - acc: 0.9075 - val_loss: 0.3319 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00024: acc did not improve\n",
      "Epoch 25/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2980 - acc: 0.9053 - val_loss: 0.3265 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00025: acc did not improve\n",
      "Epoch 26/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2827 - acc: 0.9119 - val_loss: 0.2172 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00026: acc did not improve\n",
      "Epoch 27/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2586 - acc: 0.9217 - val_loss: 0.2026 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00027: acc did not improve\n",
      "Epoch 28/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2361 - acc: 0.9333 - val_loss: 0.2092 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00028: acc improved from 0.92653 to 0.93330, saving model to best_model_LSTM\n",
      "Epoch 29/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2449 - acc: 0.9287 - val_loss: 0.2261 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00029: acc did not improve\n",
      "Epoch 30/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2491 - acc: 0.9281 - val_loss: 0.2178 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00030: acc did not improve\n",
      "Epoch 31/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2562 - acc: 0.9230 - val_loss: 0.3274 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00031: acc did not improve\n",
      "Epoch 32/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2810 - acc: 0.9123 - val_loss: 0.3333 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00032: acc did not improve\n",
      "Epoch 33/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2803 - acc: 0.9119 - val_loss: 0.3330 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00033: acc did not improve\n",
      "Epoch 34/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2767 - acc: 0.9152 - val_loss: 0.3279 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00034: acc did not improve\n",
      "Epoch 35/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2958 - acc: 0.9053 - val_loss: 0.3196 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00035: acc did not improve\n",
      "Epoch 36/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2826 - acc: 0.9112 - val_loss: 0.3254 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00036: acc did not improve\n",
      "Epoch 37/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2832 - acc: 0.9108 - val_loss: 0.3224 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00037: acc did not improve\n",
      "Epoch 38/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2752 - acc: 0.9149 - val_loss: 0.3371 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00038: acc did not improve\n",
      "Epoch 39/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2802 - acc: 0.9132 - val_loss: 0.3234 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00039: acc did not improve\n",
      "Epoch 40/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2699 - acc: 0.9147 - val_loss: 0.3258 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00040: acc did not improve\n",
      "Epoch 41/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2950 - acc: 0.9033 - val_loss: 0.3247 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00041: acc did not improve\n",
      "Epoch 42/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2811 - acc: 0.9119 - val_loss: 0.3218 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00042: acc did not improve\n",
      "Epoch 43/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2695 - acc: 0.9138 - val_loss: 0.2901 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00043: acc did not improve\n",
      "Epoch 44/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2751 - acc: 0.9134 - val_loss: 0.3225 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00044: acc did not improve\n",
      "Epoch 45/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2709 - acc: 0.9145 - val_loss: 0.2923 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00045: acc did not improve\n",
      "Epoch 46/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2742 - acc: 0.9152 - val_loss: 0.3270 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00046: acc did not improve\n",
      "Epoch 47/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2788 - acc: 0.9112 - val_loss: 0.3313 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00047: acc did not improve\n",
      "Epoch 48/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2683 - acc: 0.9158 - val_loss: 0.3096 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00048: acc did not improve\n",
      "Epoch 49/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2893 - acc: 0.9003 - val_loss: 0.3869 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00049: acc did not improve\n",
      "Epoch 50/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2858 - acc: 0.9095 - val_loss: 0.3345 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00050: acc did not improve\n",
      "Epoch 51/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2855 - acc: 0.9103 - val_loss: 0.3226 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00051: acc did not improve\n",
      "Epoch 52/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2911 - acc: 0.9068 - val_loss: 0.3291 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00052: acc did not improve\n",
      "Epoch 53/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2982 - acc: 0.9042 - val_loss: 0.3391 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00053: acc did not improve\n",
      "Epoch 54/600\n",
      "4573/4573 [==============================] - 0s 93us/step - loss: 0.3009 - acc: 0.9025 - val_loss: 0.3444 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00054: acc did not improve\n",
      "Epoch 55/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2865 - acc: 0.9092 - val_loss: 0.2560 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00055: acc did not improve\n",
      "Epoch 56/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2747 - acc: 0.9152 - val_loss: 0.2495 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00056: acc did not improve\n",
      "Epoch 57/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2586 - acc: 0.9230 - val_loss: 0.2758 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00057: acc did not improve\n",
      "Epoch 58/600\n",
      "4573/4573 [==============================] - 0s 94us/step - loss: 0.2598 - acc: 0.9206 - val_loss: 0.2428 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00058: acc did not improve\n",
      "Epoch 59/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2658 - acc: 0.9197 - val_loss: 0.2348 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00059: acc did not improve\n",
      "Epoch 60/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2437 - acc: 0.9296 - val_loss: 0.2450 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00060: acc did not improve\n",
      "Epoch 61/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2436 - acc: 0.9287 - val_loss: 0.1960 - val_acc: 0.9548\n",
      "\n",
      "Epoch 00061: acc did not improve\n",
      "Epoch 62/600\n",
      "4573/4573 [==============================] - 0s 93us/step - loss: 0.2806 - acc: 0.9132 - val_loss: 0.3295 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00062: acc did not improve\n",
      "Epoch 63/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2855 - acc: 0.9108 - val_loss: 0.3200 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00063: acc did not improve\n",
      "Epoch 64/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2820 - acc: 0.9114 - val_loss: 0.3239 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00064: acc did not improve\n",
      "Epoch 65/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2826 - acc: 0.9106 - val_loss: 0.3234 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00065: acc did not improve\n",
      "Epoch 66/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2812 - acc: 0.9117 - val_loss: 0.3257 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00066: acc did not improve\n",
      "Epoch 67/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2702 - acc: 0.9160 - val_loss: 0.2205 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00067: acc did not improve\n",
      "Epoch 68/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2453 - acc: 0.9272 - val_loss: 0.2152 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00068: acc did not improve\n",
      "Epoch 69/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2497 - acc: 0.9285 - val_loss: 0.2342 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00069: acc did not improve\n",
      "Epoch 70/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2357 - acc: 0.9331 - val_loss: 0.2312 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00070: acc did not improve\n",
      "Epoch 71/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2348 - acc: 0.9333 - val_loss: 0.2239 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00071: acc did not improve\n",
      "Epoch 72/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2425 - acc: 0.9302 - val_loss: 0.2394 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00072: acc did not improve\n",
      "Epoch 73/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2442 - acc: 0.9291 - val_loss: 0.2277 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00073: acc did not improve\n",
      "Epoch 74/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2466 - acc: 0.9287 - val_loss: 0.2202 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00074: acc did not improve\n",
      "Epoch 75/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2445 - acc: 0.9296 - val_loss: 0.2400 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00075: acc did not improve\n",
      "Epoch 76/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2456 - acc: 0.9294 - val_loss: 0.2107 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00076: acc did not improve\n",
      "Epoch 77/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2412 - acc: 0.9309 - val_loss: 0.2143 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00077: acc did not improve\n",
      "Epoch 78/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2392 - acc: 0.9309 - val_loss: 0.2089 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00078: acc did not improve\n",
      "Epoch 79/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2370 - acc: 0.9324 - val_loss: 0.2123 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00079: acc did not improve\n",
      "Epoch 80/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2360 - acc: 0.9320 - val_loss: 0.1966 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00080: acc did not improve\n",
      "Epoch 81/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2424 - acc: 0.9287 - val_loss: 0.2207 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00081: acc did not improve\n",
      "Epoch 82/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2259 - acc: 0.9355 - val_loss: 0.2074 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00082: acc improved from 0.93330 to 0.93549, saving model to best_model_LSTM\n",
      "Epoch 83/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2436 - acc: 0.9287 - val_loss: 0.1936 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00083: acc did not improve\n",
      "Epoch 84/600\n",
      "4573/4573 [==============================] - 0s 93us/step - loss: 0.2359 - acc: 0.9318 - val_loss: 0.2081 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00084: acc did not improve\n",
      "Epoch 85/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2538 - acc: 0.9248 - val_loss: 0.2031 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00085: acc did not improve\n",
      "Epoch 86/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2347 - acc: 0.9326 - val_loss: 0.2131 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00086: acc did not improve\n",
      "Epoch 87/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2357 - acc: 0.9333 - val_loss: 0.2202 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00087: acc did not improve\n",
      "Epoch 88/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2519 - acc: 0.9254 - val_loss: 0.2059 - val_acc: 0.9470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00088: acc did not improve\n",
      "Epoch 89/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2340 - acc: 0.9320 - val_loss: 0.2336 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00089: acc did not improve\n",
      "Epoch 90/600\n",
      "4573/4573 [==============================] - 0s 93us/step - loss: 0.2434 - acc: 0.9283 - val_loss: 0.2136 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00090: acc did not improve\n",
      "Epoch 91/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2409 - acc: 0.9316 - val_loss: 0.2123 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00091: acc did not improve\n",
      "Epoch 92/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.3099 - acc: 0.8926 - val_loss: 0.2780 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00092: acc did not improve\n",
      "Epoch 93/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2680 - acc: 0.9197 - val_loss: 0.2382 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00093: acc did not improve\n",
      "Epoch 94/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2582 - acc: 0.9230 - val_loss: 0.2219 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00094: acc did not improve\n",
      "Epoch 95/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2570 - acc: 0.9213 - val_loss: 0.2331 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00095: acc did not improve\n",
      "Epoch 96/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2455 - acc: 0.9276 - val_loss: 0.2112 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00096: acc did not improve\n",
      "Epoch 97/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2537 - acc: 0.9252 - val_loss: 0.2021 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00097: acc did not improve\n",
      "Epoch 98/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2538 - acc: 0.9243 - val_loss: 0.2515 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00098: acc did not improve\n",
      "Epoch 99/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2537 - acc: 0.9230 - val_loss: 0.2226 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00099: acc did not improve\n",
      "Epoch 100/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2596 - acc: 0.9226 - val_loss: 0.2348 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00100: acc did not improve\n",
      "Epoch 101/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2621 - acc: 0.9226 - val_loss: 0.2117 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00101: acc did not improve\n",
      "Epoch 102/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2526 - acc: 0.9254 - val_loss: 0.2119 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00102: acc did not improve\n",
      "Epoch 103/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2525 - acc: 0.9250 - val_loss: 0.2050 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00103: acc did not improve\n",
      "Epoch 104/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2491 - acc: 0.9254 - val_loss: 0.2076 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00104: acc did not improve\n",
      "Epoch 105/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2532 - acc: 0.9261 - val_loss: 0.2266 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00105: acc did not improve\n",
      "Epoch 106/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2383 - acc: 0.9300 - val_loss: 0.2080 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00106: acc did not improve\n",
      "Epoch 107/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2344 - acc: 0.9329 - val_loss: 0.2182 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00107: acc did not improve\n",
      "Epoch 108/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2547 - acc: 0.9243 - val_loss: 0.2213 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00108: acc did not improve\n",
      "Epoch 109/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2564 - acc: 0.9235 - val_loss: 0.2031 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00109: acc did not improve\n",
      "Epoch 110/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2422 - acc: 0.9287 - val_loss: 0.2225 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00110: acc did not improve\n",
      "Epoch 111/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2448 - acc: 0.9274 - val_loss: 0.2239 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00111: acc did not improve\n",
      "Epoch 112/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2509 - acc: 0.9252 - val_loss: 0.2269 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00112: acc did not improve\n",
      "Epoch 113/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2490 - acc: 0.9261 - val_loss: 0.2126 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00113: acc did not improve\n",
      "Epoch 114/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2405 - acc: 0.9302 - val_loss: 0.2258 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00114: acc did not improve\n",
      "Epoch 115/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2471 - acc: 0.9274 - val_loss: 0.2113 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00115: acc did not improve\n",
      "Epoch 116/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2524 - acc: 0.9263 - val_loss: 0.1988 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00116: acc did not improve\n",
      "Epoch 117/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2409 - acc: 0.9276 - val_loss: 0.1946 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00117: acc did not improve\n",
      "Epoch 118/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2472 - acc: 0.9252 - val_loss: 0.2065 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00118: acc did not improve\n",
      "Epoch 119/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2340 - acc: 0.9324 - val_loss: 0.2045 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00119: acc did not improve\n",
      "Epoch 120/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2353 - acc: 0.9340 - val_loss: 0.2034 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00120: acc did not improve\n",
      "Epoch 121/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2300 - acc: 0.9351 - val_loss: 0.2054 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00121: acc did not improve\n",
      "Epoch 122/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2463 - acc: 0.9285 - val_loss: 0.2288 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00122: acc did not improve\n",
      "Epoch 123/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2424 - acc: 0.9302 - val_loss: 0.2190 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00123: acc did not improve\n",
      "Epoch 124/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2485 - acc: 0.9263 - val_loss: 0.2110 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00124: acc did not improve\n",
      "Epoch 125/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2542 - acc: 0.9246 - val_loss: 0.2107 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00125: acc did not improve\n",
      "Epoch 126/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2367 - acc: 0.9335 - val_loss: 0.2144 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00126: acc did not improve\n",
      "Epoch 127/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2398 - acc: 0.9305 - val_loss: 0.2080 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00127: acc did not improve\n",
      "Epoch 128/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2296 - acc: 0.9361 - val_loss: 0.2028 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00128: acc improved from 0.93549 to 0.93615, saving model to best_model_LSTM\n",
      "Epoch 129/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2448 - acc: 0.9285 - val_loss: 0.2108 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00129: acc did not improve\n",
      "Epoch 130/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2461 - acc: 0.9274 - val_loss: 0.2144 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00130: acc did not improve\n",
      "Epoch 131/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2362 - acc: 0.9324 - val_loss: 0.2107 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00131: acc did not improve\n",
      "Epoch 132/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2420 - acc: 0.9302 - val_loss: 0.2263 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00132: acc did not improve\n",
      "Epoch 133/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2425 - acc: 0.9287 - val_loss: 0.2031 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00133: acc did not improve\n",
      "Epoch 134/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2379 - acc: 0.9313 - val_loss: 0.2223 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00134: acc did not improve\n",
      "Epoch 135/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2395 - acc: 0.9294 - val_loss: 0.2284 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00135: acc did not improve\n",
      "Epoch 136/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2364 - acc: 0.9305 - val_loss: 0.2041 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00136: acc did not improve\n",
      "Epoch 137/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2371 - acc: 0.9318 - val_loss: 0.2015 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00137: acc did not improve\n",
      "Epoch 138/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2449 - acc: 0.9276 - val_loss: 0.2052 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00138: acc did not improve\n",
      "Epoch 139/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2407 - acc: 0.9298 - val_loss: 0.2376 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00139: acc did not improve\n",
      "Epoch 140/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2437 - acc: 0.9289 - val_loss: 0.2007 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00140: acc did not improve\n",
      "Epoch 141/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2497 - acc: 0.9274 - val_loss: 0.2384 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00141: acc did not improve\n",
      "Epoch 142/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2343 - acc: 0.9322 - val_loss: 0.1998 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00142: acc did not improve\n",
      "Epoch 143/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2447 - acc: 0.9278 - val_loss: 0.2241 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00143: acc did not improve\n",
      "Epoch 144/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2340 - acc: 0.9333 - val_loss: 0.2126 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00144: acc did not improve\n",
      "Epoch 145/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2281 - acc: 0.9353 - val_loss: 0.2246 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00145: acc did not improve\n",
      "Epoch 146/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2389 - acc: 0.9313 - val_loss: 0.2015 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00146: acc did not improve\n",
      "Epoch 147/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2476 - acc: 0.9259 - val_loss: 0.2394 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00147: acc did not improve\n",
      "Epoch 148/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2369 - acc: 0.9316 - val_loss: 0.2100 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00148: acc did not improve\n",
      "Epoch 149/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2402 - acc: 0.9302 - val_loss: 0.2035 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00149: acc did not improve\n",
      "Epoch 150/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2524 - acc: 0.9254 - val_loss: 0.2126 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00150: acc did not improve\n",
      "Epoch 151/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2379 - acc: 0.9322 - val_loss: 0.2098 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00151: acc did not improve\n",
      "Epoch 152/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2355 - acc: 0.9322 - val_loss: 0.2084 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00152: acc did not improve\n",
      "Epoch 153/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2446 - acc: 0.9302 - val_loss: 0.2049 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00153: acc did not improve\n",
      "Epoch 154/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2415 - acc: 0.9305 - val_loss: 0.2259 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00154: acc did not improve\n",
      "Epoch 155/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2369 - acc: 0.9300 - val_loss: 0.2065 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00155: acc did not improve\n",
      "Epoch 156/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2308 - acc: 0.9340 - val_loss: 0.2071 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00156: acc did not improve\n",
      "Epoch 157/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2333 - acc: 0.9309 - val_loss: 0.2036 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00157: acc did not improve\n",
      "Epoch 158/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2604 - acc: 0.9211 - val_loss: 0.3255 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00158: acc did not improve\n",
      "Epoch 159/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2425 - acc: 0.9294 - val_loss: 0.2066 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00159: acc did not improve\n",
      "Epoch 160/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2378 - acc: 0.9322 - val_loss: 0.2255 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00160: acc did not improve\n",
      "Epoch 161/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2384 - acc: 0.9313 - val_loss: 0.1972 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00161: acc did not improve\n",
      "Epoch 162/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2441 - acc: 0.9289 - val_loss: 0.2291 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00162: acc did not improve\n",
      "Epoch 163/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2411 - acc: 0.9296 - val_loss: 0.2012 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00163: acc did not improve\n",
      "Epoch 164/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2369 - acc: 0.9320 - val_loss: 0.2119 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00164: acc did not improve\n",
      "Epoch 165/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2380 - acc: 0.9329 - val_loss: 0.2164 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00165: acc did not improve\n",
      "Epoch 166/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2356 - acc: 0.9340 - val_loss: 0.1976 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00166: acc did not improve\n",
      "Epoch 167/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2329 - acc: 0.9344 - val_loss: 0.2217 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00167: acc did not improve\n",
      "Epoch 168/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2334 - acc: 0.9346 - val_loss: 0.2236 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00168: acc did not improve\n",
      "Epoch 169/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2450 - acc: 0.9276 - val_loss: 0.2338 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00169: acc did not improve\n",
      "Epoch 170/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2462 - acc: 0.9278 - val_loss: 0.1980 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00170: acc did not improve\n",
      "Epoch 171/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2392 - acc: 0.9298 - val_loss: 0.2025 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00171: acc did not improve\n",
      "Epoch 172/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2370 - acc: 0.9326 - val_loss: 0.2050 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00172: acc did not improve\n",
      "Epoch 173/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2424 - acc: 0.9298 - val_loss: 0.2036 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00173: acc did not improve\n",
      "Epoch 174/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2348 - acc: 0.9337 - val_loss: 0.1950 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00174: acc did not improve\n",
      "Epoch 175/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2355 - acc: 0.9322 - val_loss: 0.2084 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00175: acc did not improve\n",
      "Epoch 176/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2301 - acc: 0.9351 - val_loss: 0.2156 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00176: acc did not improve\n",
      "Epoch 177/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2322 - acc: 0.9344 - val_loss: 0.2021 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00177: acc did not improve\n",
      "Epoch 178/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2370 - acc: 0.9316 - val_loss: 0.2024 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00178: acc did not improve\n",
      "Epoch 179/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2336 - acc: 0.9335 - val_loss: 0.2038 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00179: acc did not improve\n",
      "Epoch 180/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2308 - acc: 0.9344 - val_loss: 0.2047 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00180: acc did not improve\n",
      "Epoch 181/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2332 - acc: 0.9324 - val_loss: 0.2020 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00181: acc did not improve\n",
      "Epoch 182/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2364 - acc: 0.9331 - val_loss: 0.2023 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00182: acc did not improve\n",
      "Epoch 183/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2390 - acc: 0.9322 - val_loss: 0.2032 - val_acc: 0.9528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00183: acc did not improve\n",
      "Epoch 184/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2593 - acc: 0.9219 - val_loss: 0.2124 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00184: acc did not improve\n",
      "Epoch 185/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2468 - acc: 0.9281 - val_loss: 0.2048 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00185: acc did not improve\n",
      "Epoch 186/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2394 - acc: 0.9309 - val_loss: 0.2378 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00186: acc did not improve\n",
      "Epoch 187/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2460 - acc: 0.9281 - val_loss: 0.2034 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00187: acc did not improve\n",
      "Epoch 188/600\n",
      "4573/4573 [==============================] - 0s 93us/step - loss: 0.2417 - acc: 0.9289 - val_loss: 0.2186 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00188: acc did not improve\n",
      "Epoch 189/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2511 - acc: 0.9283 - val_loss: 0.2127 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00189: acc did not improve\n",
      "Epoch 190/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2490 - acc: 0.9263 - val_loss: 0.2027 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00190: acc did not improve\n",
      "Epoch 191/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2389 - acc: 0.9302 - val_loss: 0.2048 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00191: acc did not improve\n",
      "Epoch 192/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2489 - acc: 0.9278 - val_loss: 0.2081 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00192: acc did not improve\n",
      "Epoch 193/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2402 - acc: 0.9300 - val_loss: 0.2052 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00193: acc did not improve\n",
      "Epoch 194/600\n",
      "4573/4573 [==============================] - 0s 93us/step - loss: 0.2614 - acc: 0.9224 - val_loss: 0.1983 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00194: acc did not improve\n",
      "Epoch 195/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2461 - acc: 0.9276 - val_loss: 0.2140 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00195: acc did not improve\n",
      "Epoch 196/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2479 - acc: 0.9278 - val_loss: 0.2058 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00196: acc did not improve\n",
      "Epoch 197/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2365 - acc: 0.9329 - val_loss: 0.2061 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00197: acc did not improve\n",
      "Epoch 198/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2439 - acc: 0.9287 - val_loss: 0.2290 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00198: acc did not improve\n",
      "Epoch 199/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2475 - acc: 0.9283 - val_loss: 0.2178 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00199: acc did not improve\n",
      "Epoch 200/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2563 - acc: 0.9235 - val_loss: 0.2147 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00200: acc did not improve\n",
      "Epoch 201/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2425 - acc: 0.9285 - val_loss: 0.2203 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00201: acc did not improve\n",
      "Epoch 202/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2599 - acc: 0.9219 - val_loss: 0.2334 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00202: acc did not improve\n",
      "Epoch 203/600\n",
      "4573/4573 [==============================] - 0s 95us/step - loss: 0.2544 - acc: 0.9243 - val_loss: 0.2340 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00203: acc did not improve\n",
      "Epoch 204/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2448 - acc: 0.9278 - val_loss: 0.2137 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00204: acc did not improve\n",
      "Epoch 205/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2390 - acc: 0.9302 - val_loss: 0.2138 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00205: acc did not improve\n",
      "Epoch 206/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2414 - acc: 0.9305 - val_loss: 0.2178 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00206: acc did not improve\n",
      "Epoch 207/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2458 - acc: 0.9281 - val_loss: 0.2069 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00207: acc did not improve\n",
      "Epoch 208/600\n",
      "4573/4573 [==============================] - 0s 92us/step - loss: 0.2510 - acc: 0.9278 - val_loss: 0.1992 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00208: acc did not improve\n",
      "Epoch 209/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2466 - acc: 0.9291 - val_loss: 0.2174 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00209: acc did not improve\n",
      "Epoch 210/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2496 - acc: 0.9278 - val_loss: 0.2064 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00210: acc did not improve\n",
      "Epoch 211/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2515 - acc: 0.9261 - val_loss: 0.2375 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00211: acc did not improve\n",
      "Epoch 212/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2534 - acc: 0.9254 - val_loss: 0.2182 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00212: acc did not improve\n",
      "Epoch 213/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2501 - acc: 0.9254 - val_loss: 0.2244 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00213: acc did not improve\n",
      "Epoch 214/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2521 - acc: 0.9259 - val_loss: 0.2002 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00214: acc did not improve\n",
      "Epoch 215/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2552 - acc: 0.9239 - val_loss: 0.2103 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00215: acc did not improve\n",
      "Epoch 216/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2643 - acc: 0.9208 - val_loss: 0.2077 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00216: acc did not improve\n",
      "Epoch 217/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2497 - acc: 0.9274 - val_loss: 0.2391 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00217: acc did not improve\n",
      "Epoch 218/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2702 - acc: 0.9193 - val_loss: 0.2344 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00218: acc did not improve\n",
      "Epoch 219/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2456 - acc: 0.9287 - val_loss: 0.2037 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00219: acc did not improve\n",
      "Epoch 220/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2474 - acc: 0.9272 - val_loss: 0.2087 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00220: acc did not improve\n",
      "Epoch 221/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2566 - acc: 0.9248 - val_loss: 0.2223 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00221: acc did not improve\n",
      "Epoch 222/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2523 - acc: 0.9246 - val_loss: 0.2138 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00222: acc did not improve\n",
      "Epoch 223/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2419 - acc: 0.9305 - val_loss: 0.2119 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00223: acc did not improve\n",
      "Epoch 224/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2424 - acc: 0.9309 - val_loss: 0.2086 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00224: acc did not improve\n",
      "Epoch 225/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2421 - acc: 0.9305 - val_loss: 0.2048 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00225: acc did not improve\n",
      "Epoch 226/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2399 - acc: 0.9309 - val_loss: 0.2344 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00226: acc did not improve\n",
      "Epoch 227/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2428 - acc: 0.9287 - val_loss: 0.2163 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00227: acc did not improve\n",
      "Epoch 228/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2549 - acc: 0.9241 - val_loss: 0.2273 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00228: acc did not improve\n",
      "Epoch 229/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2414 - acc: 0.9289 - val_loss: 0.2353 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00229: acc did not improve\n",
      "Epoch 230/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2421 - acc: 0.9296 - val_loss: 0.2040 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00230: acc did not improve\n",
      "Epoch 231/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2541 - acc: 0.9252 - val_loss: 0.2166 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00231: acc did not improve\n",
      "Epoch 232/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2448 - acc: 0.9283 - val_loss: 0.2078 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00232: acc did not improve\n",
      "Epoch 233/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2296 - acc: 0.9359 - val_loss: 0.2010 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00233: acc did not improve\n",
      "Epoch 234/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2439 - acc: 0.9291 - val_loss: 0.2513 - val_acc: 0.9293\n",
      "\n",
      "Epoch 00234: acc did not improve\n",
      "Epoch 235/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2534 - acc: 0.9270 - val_loss: 0.2096 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00235: acc did not improve\n",
      "Epoch 236/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2523 - acc: 0.9263 - val_loss: 0.2074 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00236: acc did not improve\n",
      "Epoch 237/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2584 - acc: 0.9252 - val_loss: 0.2230 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00237: acc did not improve\n",
      "Epoch 238/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2433 - acc: 0.9298 - val_loss: 0.2062 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00238: acc did not improve\n",
      "Epoch 239/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2470 - acc: 0.9287 - val_loss: 0.2209 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00239: acc did not improve\n",
      "Epoch 240/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2444 - acc: 0.9265 - val_loss: 0.2234 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00240: acc did not improve\n",
      "Epoch 241/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2541 - acc: 0.9241 - val_loss: 0.2136 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00241: acc did not improve\n",
      "Epoch 242/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2518 - acc: 0.9257 - val_loss: 0.2061 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00242: acc did not improve\n",
      "Epoch 243/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2535 - acc: 0.9239 - val_loss: 0.2387 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00243: acc did not improve\n",
      "Epoch 244/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2450 - acc: 0.9294 - val_loss: 0.2071 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00244: acc did not improve\n",
      "Epoch 245/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2510 - acc: 0.9252 - val_loss: 0.2052 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00245: acc did not improve\n",
      "Epoch 246/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2443 - acc: 0.9261 - val_loss: 0.2339 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00246: acc did not improve\n",
      "Epoch 247/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2390 - acc: 0.9318 - val_loss: 0.2004 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00247: acc did not improve\n",
      "Epoch 248/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2440 - acc: 0.9291 - val_loss: 0.2029 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00248: acc did not improve\n",
      "Epoch 249/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2450 - acc: 0.9300 - val_loss: 0.2059 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00249: acc did not improve\n",
      "Epoch 250/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2431 - acc: 0.9285 - val_loss: 0.2228 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00250: acc did not improve\n",
      "Epoch 251/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2493 - acc: 0.9263 - val_loss: 0.2333 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00251: acc did not improve\n",
      "Epoch 252/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2413 - acc: 0.9291 - val_loss: 0.2054 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00252: acc did not improve\n",
      "Epoch 253/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2407 - acc: 0.9300 - val_loss: 0.2054 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00253: acc did not improve\n",
      "Epoch 254/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2463 - acc: 0.9285 - val_loss: 0.2034 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00254: acc did not improve\n",
      "Epoch 255/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2435 - acc: 0.9287 - val_loss: 0.2373 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00255: acc did not improve\n",
      "Epoch 256/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2358 - acc: 0.9329 - val_loss: 0.2015 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00256: acc did not improve\n",
      "Epoch 257/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2447 - acc: 0.9296 - val_loss: 0.2065 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00257: acc did not improve\n",
      "Epoch 258/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2536 - acc: 0.9230 - val_loss: 0.2286 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00258: acc did not improve\n",
      "Epoch 259/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2506 - acc: 0.9265 - val_loss: 0.2285 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00259: acc did not improve\n",
      "Epoch 260/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2440 - acc: 0.9289 - val_loss: 0.2360 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00260: acc did not improve\n",
      "Epoch 261/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2446 - acc: 0.9285 - val_loss: 0.2130 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00261: acc did not improve\n",
      "Epoch 262/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2576 - acc: 0.9226 - val_loss: 0.2281 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00262: acc did not improve\n",
      "Epoch 263/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2509 - acc: 0.9241 - val_loss: 0.2245 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00263: acc did not improve\n",
      "Epoch 264/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2414 - acc: 0.9298 - val_loss: 0.2009 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00264: acc did not improve\n",
      "Epoch 265/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2485 - acc: 0.9261 - val_loss: 0.2368 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00265: acc did not improve\n",
      "Epoch 266/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2521 - acc: 0.9246 - val_loss: 0.2273 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00266: acc did not improve\n",
      "Epoch 267/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2524 - acc: 0.9261 - val_loss: 0.2382 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00267: acc did not improve\n",
      "Epoch 268/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2398 - acc: 0.9316 - val_loss: 0.2003 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00268: acc did not improve\n",
      "Epoch 269/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2440 - acc: 0.9287 - val_loss: 0.2219 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00269: acc did not improve\n",
      "Epoch 270/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2433 - acc: 0.9305 - val_loss: 0.2027 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00270: acc did not improve\n",
      "Epoch 271/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2378 - acc: 0.9329 - val_loss: 0.2036 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00271: acc did not improve\n",
      "Epoch 272/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2448 - acc: 0.9283 - val_loss: 0.2376 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00272: acc did not improve\n",
      "Epoch 273/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2467 - acc: 0.9291 - val_loss: 0.2040 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00273: acc did not improve\n",
      "Epoch 274/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2446 - acc: 0.9283 - val_loss: 0.2242 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00274: acc did not improve\n",
      "Epoch 275/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2467 - acc: 0.9287 - val_loss: 0.2330 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00275: acc did not improve\n",
      "Epoch 276/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2503 - acc: 0.9263 - val_loss: 0.2250 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00276: acc did not improve\n",
      "Epoch 277/600\n",
      "4573/4573 [==============================] - 0s 93us/step - loss: 0.2518 - acc: 0.9254 - val_loss: 0.2340 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00277: acc did not improve\n",
      "Epoch 278/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2556 - acc: 0.9237 - val_loss: 0.2389 - val_acc: 0.9371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00278: acc did not improve\n",
      "Epoch 279/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2498 - acc: 0.9257 - val_loss: 0.2056 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00279: acc did not improve\n",
      "Epoch 280/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2514 - acc: 0.9257 - val_loss: 0.2038 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00280: acc did not improve\n",
      "Epoch 281/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2444 - acc: 0.9285 - val_loss: 0.2134 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00281: acc did not improve\n",
      "Epoch 282/600\n",
      "4573/4573 [==============================] - 0s 85us/step - loss: 0.2474 - acc: 0.9283 - val_loss: 0.2252 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00282: acc did not improve\n",
      "Epoch 283/600\n",
      "4573/4573 [==============================] - 0s 83us/step - loss: 0.2437 - acc: 0.9307 - val_loss: 0.2024 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00283: acc did not improve\n",
      "Epoch 284/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2439 - acc: 0.9291 - val_loss: 0.2077 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00284: acc did not improve\n",
      "Epoch 285/600\n",
      "4573/4573 [==============================] - 0s 85us/step - loss: 0.2478 - acc: 0.9281 - val_loss: 0.2089 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00285: acc did not improve\n",
      "Epoch 286/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2493 - acc: 0.9278 - val_loss: 0.2112 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00286: acc did not improve\n",
      "Epoch 287/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2425 - acc: 0.9281 - val_loss: 0.2090 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00287: acc did not improve\n",
      "Epoch 288/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2508 - acc: 0.9265 - val_loss: 0.2438 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00288: acc did not improve\n",
      "Epoch 289/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2460 - acc: 0.9287 - val_loss: 0.1978 - val_acc: 0.9548\n",
      "\n",
      "Epoch 00289: acc did not improve\n",
      "Epoch 290/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2360 - acc: 0.9337 - val_loss: 0.1978 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00290: acc did not improve\n",
      "Epoch 291/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2369 - acc: 0.9326 - val_loss: 0.2068 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00291: acc did not improve\n",
      "Epoch 292/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2371 - acc: 0.9322 - val_loss: 0.1991 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00292: acc did not improve\n",
      "Epoch 293/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2573 - acc: 0.9250 - val_loss: 0.2018 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00293: acc did not improve\n",
      "Epoch 294/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2504 - acc: 0.9267 - val_loss: 0.2185 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00294: acc did not improve\n",
      "Epoch 295/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2468 - acc: 0.9283 - val_loss: 0.2038 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00295: acc did not improve\n",
      "Epoch 296/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2484 - acc: 0.9261 - val_loss: 0.2274 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00296: acc did not improve\n",
      "Epoch 297/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2305 - acc: 0.9355 - val_loss: 0.1942 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00297: acc did not improve\n",
      "Epoch 298/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2358 - acc: 0.9320 - val_loss: 0.2068 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00298: acc did not improve\n",
      "Epoch 299/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2528 - acc: 0.9232 - val_loss: 0.2404 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00299: acc did not improve\n",
      "Epoch 300/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2452 - acc: 0.9291 - val_loss: 0.2042 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00300: acc did not improve\n",
      "Epoch 301/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2473 - acc: 0.9287 - val_loss: 0.2105 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00301: acc did not improve\n",
      "Epoch 302/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2510 - acc: 0.9252 - val_loss: 0.2082 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00302: acc did not improve\n",
      "Epoch 303/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2445 - acc: 0.9274 - val_loss: 0.2020 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00303: acc did not improve\n",
      "Epoch 304/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2522 - acc: 0.9272 - val_loss: 0.2435 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00304: acc did not improve\n",
      "Epoch 305/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2421 - acc: 0.9289 - val_loss: 0.2225 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00305: acc did not improve\n",
      "Epoch 306/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2431 - acc: 0.9287 - val_loss: 0.2312 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00306: acc did not improve\n",
      "Epoch 307/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2448 - acc: 0.9296 - val_loss: 0.2008 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00307: acc did not improve\n",
      "Epoch 308/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2423 - acc: 0.9289 - val_loss: 0.2221 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00308: acc did not improve\n",
      "Epoch 309/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2385 - acc: 0.9316 - val_loss: 0.2051 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00309: acc did not improve\n",
      "Epoch 310/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2423 - acc: 0.9298 - val_loss: 0.2291 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00310: acc did not improve\n",
      "Epoch 311/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2348 - acc: 0.9322 - val_loss: 0.2251 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00311: acc did not improve\n",
      "Epoch 312/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2419 - acc: 0.9313 - val_loss: 0.2021 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00312: acc did not improve\n",
      "Epoch 313/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2431 - acc: 0.9281 - val_loss: 0.2465 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00313: acc did not improve\n",
      "Epoch 314/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2500 - acc: 0.9263 - val_loss: 0.2434 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00314: acc did not improve\n",
      "Epoch 315/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2364 - acc: 0.9326 - val_loss: 0.2046 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00315: acc did not improve\n",
      "Epoch 316/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2370 - acc: 0.9333 - val_loss: 0.2030 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00316: acc did not improve\n",
      "Epoch 317/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2446 - acc: 0.9285 - val_loss: 0.2334 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00317: acc did not improve\n",
      "Epoch 318/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2469 - acc: 0.9289 - val_loss: 0.2249 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00318: acc did not improve\n",
      "Epoch 319/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2424 - acc: 0.9298 - val_loss: 0.2273 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00319: acc did not improve\n",
      "Epoch 320/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2498 - acc: 0.9276 - val_loss: 0.2229 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00320: acc did not improve\n",
      "Epoch 321/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2489 - acc: 0.9285 - val_loss: 0.2064 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00321: acc did not improve\n",
      "Epoch 322/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2440 - acc: 0.9281 - val_loss: 0.2220 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00322: acc did not improve\n",
      "Epoch 323/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2509 - acc: 0.9285 - val_loss: 0.2049 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00323: acc did not improve\n",
      "Epoch 324/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2420 - acc: 0.9298 - val_loss: 0.2136 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00324: acc did not improve\n",
      "Epoch 325/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2532 - acc: 0.9265 - val_loss: 0.2004 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00325: acc did not improve\n",
      "Epoch 326/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2436 - acc: 0.9285 - val_loss: 0.2046 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00326: acc did not improve\n",
      "Epoch 327/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2472 - acc: 0.9294 - val_loss: 0.2117 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00327: acc did not improve\n",
      "Epoch 328/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2456 - acc: 0.9298 - val_loss: 0.2237 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00328: acc did not improve\n",
      "Epoch 329/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2444 - acc: 0.9287 - val_loss: 0.2129 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00329: acc did not improve\n",
      "Epoch 330/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2454 - acc: 0.9278 - val_loss: 0.2048 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00330: acc did not improve\n",
      "Epoch 331/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2464 - acc: 0.9283 - val_loss: 0.2047 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00331: acc did not improve\n",
      "Epoch 332/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2496 - acc: 0.9287 - val_loss: 0.2035 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00332: acc did not improve\n",
      "Epoch 333/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2412 - acc: 0.9313 - val_loss: 0.2070 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00333: acc did not improve\n",
      "Epoch 334/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2466 - acc: 0.9296 - val_loss: 0.2077 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00334: acc did not improve\n",
      "Epoch 335/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2508 - acc: 0.9270 - val_loss: 0.2120 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00335: acc did not improve\n",
      "Epoch 336/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2526 - acc: 0.9252 - val_loss: 0.2157 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00336: acc did not improve\n",
      "Epoch 337/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2393 - acc: 0.9309 - val_loss: 0.2165 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00337: acc did not improve\n",
      "Epoch 338/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2496 - acc: 0.9263 - val_loss: 0.2174 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00338: acc did not improve\n",
      "Epoch 339/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2477 - acc: 0.9281 - val_loss: 0.2318 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00339: acc did not improve\n",
      "Epoch 340/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2493 - acc: 0.9270 - val_loss: 0.2303 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00340: acc did not improve\n",
      "Epoch 341/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2397 - acc: 0.9324 - val_loss: 0.2074 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00341: acc did not improve\n",
      "Epoch 342/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2453 - acc: 0.9294 - val_loss: 0.2000 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00342: acc did not improve\n",
      "Epoch 343/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2407 - acc: 0.9316 - val_loss: 0.2000 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00343: acc did not improve\n",
      "Epoch 344/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2427 - acc: 0.9294 - val_loss: 0.2495 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00344: acc did not improve\n",
      "Epoch 345/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2468 - acc: 0.9283 - val_loss: 0.2261 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00345: acc did not improve\n",
      "Epoch 346/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2543 - acc: 0.9246 - val_loss: 0.2187 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00346: acc did not improve\n",
      "Epoch 347/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2452 - acc: 0.9289 - val_loss: 0.2069 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00347: acc did not improve\n",
      "Epoch 348/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2440 - acc: 0.9289 - val_loss: 0.2263 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00348: acc did not improve\n",
      "Epoch 349/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2405 - acc: 0.9302 - val_loss: 0.2061 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00349: acc did not improve\n",
      "Epoch 350/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2446 - acc: 0.9302 - val_loss: 0.2010 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00350: acc did not improve\n",
      "Epoch 351/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2333 - acc: 0.9344 - val_loss: 0.2059 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00351: acc did not improve\n",
      "Epoch 352/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2364 - acc: 0.9324 - val_loss: 0.2001 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00352: acc did not improve\n",
      "Epoch 353/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2405 - acc: 0.9305 - val_loss: 0.2024 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00353: acc did not improve\n",
      "Epoch 354/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2475 - acc: 0.9287 - val_loss: 0.1972 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00354: acc did not improve\n",
      "Epoch 355/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2362 - acc: 0.9326 - val_loss: 0.2079 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00355: acc did not improve\n",
      "Epoch 356/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2356 - acc: 0.9340 - val_loss: 0.2039 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00356: acc did not improve\n",
      "Epoch 357/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2405 - acc: 0.9309 - val_loss: 0.2038 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00357: acc did not improve\n",
      "Epoch 358/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2381 - acc: 0.9313 - val_loss: 0.2104 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00358: acc did not improve\n",
      "Epoch 359/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2455 - acc: 0.9285 - val_loss: 0.2051 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00359: acc did not improve\n",
      "Epoch 360/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2330 - acc: 0.9340 - val_loss: 0.1992 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00360: acc did not improve\n",
      "Epoch 361/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2448 - acc: 0.9276 - val_loss: 0.2290 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00361: acc did not improve\n",
      "Epoch 362/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2521 - acc: 0.9259 - val_loss: 0.2260 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00362: acc did not improve\n",
      "Epoch 363/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2349 - acc: 0.9329 - val_loss: 0.2057 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00363: acc did not improve\n",
      "Epoch 364/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2450 - acc: 0.9289 - val_loss: 0.2403 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00364: acc did not improve\n",
      "Epoch 365/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2551 - acc: 0.9248 - val_loss: 0.2036 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00365: acc did not improve\n",
      "Epoch 366/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2422 - acc: 0.9296 - val_loss: 0.2241 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00366: acc did not improve\n",
      "Epoch 367/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2475 - acc: 0.9270 - val_loss: 0.2198 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00367: acc did not improve\n",
      "Epoch 368/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2451 - acc: 0.9283 - val_loss: 0.2165 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00368: acc did not improve\n",
      "Epoch 369/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2426 - acc: 0.9289 - val_loss: 0.2042 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00369: acc did not improve\n",
      "Epoch 370/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2390 - acc: 0.9320 - val_loss: 0.2145 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00370: acc did not improve\n",
      "Epoch 371/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2497 - acc: 0.9259 - val_loss: 0.2000 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00371: acc did not improve\n",
      "Epoch 372/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2312 - acc: 0.9344 - val_loss: 0.2094 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00372: acc did not improve\n",
      "Epoch 373/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2491 - acc: 0.9274 - val_loss: 0.2057 - val_acc: 0.9528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00373: acc did not improve\n",
      "Epoch 374/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2517 - acc: 0.9267 - val_loss: 0.1997 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00374: acc did not improve\n",
      "Epoch 375/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2486 - acc: 0.9274 - val_loss: 0.2112 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00375: acc did not improve\n",
      "Epoch 376/600\n",
      "4573/4573 [==============================] - 0s 90us/step - loss: 0.2460 - acc: 0.9294 - val_loss: 0.1992 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00376: acc did not improve\n",
      "Epoch 377/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2415 - acc: 0.9313 - val_loss: 0.1979 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00377: acc did not improve\n",
      "Epoch 378/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2452 - acc: 0.9283 - val_loss: 0.2301 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00378: acc did not improve\n",
      "Epoch 379/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2450 - acc: 0.9281 - val_loss: 0.2203 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00379: acc did not improve\n",
      "Epoch 380/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2439 - acc: 0.9296 - val_loss: 0.2019 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00380: acc did not improve\n",
      "Epoch 381/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2429 - acc: 0.9289 - val_loss: 0.2025 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00381: acc did not improve\n",
      "Epoch 382/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2502 - acc: 0.9270 - val_loss: 0.2365 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00382: acc did not improve\n",
      "Epoch 383/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2479 - acc: 0.9267 - val_loss: 0.2311 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00383: acc did not improve\n",
      "Epoch 384/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2343 - acc: 0.9331 - val_loss: 0.2117 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00384: acc did not improve\n",
      "Epoch 385/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2474 - acc: 0.9263 - val_loss: 0.2111 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00385: acc did not improve\n",
      "Epoch 386/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2432 - acc: 0.9302 - val_loss: 0.2210 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00386: acc did not improve\n",
      "Epoch 387/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2465 - acc: 0.9267 - val_loss: 0.2433 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00387: acc did not improve\n",
      "Epoch 388/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2316 - acc: 0.9342 - val_loss: 0.2067 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00388: acc did not improve\n",
      "Epoch 389/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2479 - acc: 0.9278 - val_loss: 0.2031 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00389: acc did not improve\n",
      "Epoch 390/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2440 - acc: 0.9287 - val_loss: 0.2338 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00390: acc did not improve\n",
      "Epoch 391/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2450 - acc: 0.9294 - val_loss: 0.2021 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00391: acc did not improve\n",
      "Epoch 392/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2328 - acc: 0.9333 - val_loss: 0.1998 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00392: acc did not improve\n",
      "Epoch 393/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2449 - acc: 0.9289 - val_loss: 0.2006 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00393: acc did not improve\n",
      "Epoch 394/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2462 - acc: 0.9285 - val_loss: 0.2226 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00394: acc did not improve\n",
      "Epoch 395/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2405 - acc: 0.9309 - val_loss: 0.2051 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00395: acc did not improve\n",
      "Epoch 396/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2418 - acc: 0.9311 - val_loss: 0.2064 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00396: acc did not improve\n",
      "Epoch 397/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2461 - acc: 0.9291 - val_loss: 0.2055 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00397: acc did not improve\n",
      "Epoch 398/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2325 - acc: 0.9340 - val_loss: 0.2122 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00398: acc did not improve\n",
      "Epoch 399/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2392 - acc: 0.9320 - val_loss: 0.2125 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00399: acc did not improve\n",
      "Epoch 400/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2469 - acc: 0.9285 - val_loss: 0.2054 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00400: acc did not improve\n",
      "Epoch 401/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2392 - acc: 0.9300 - val_loss: 0.2302 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00401: acc did not improve\n",
      "Epoch 402/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2510 - acc: 0.9267 - val_loss: 0.2323 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00402: acc did not improve\n",
      "Epoch 403/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2406 - acc: 0.9298 - val_loss: 0.2015 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00403: acc did not improve\n",
      "Epoch 404/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2427 - acc: 0.9305 - val_loss: 0.1994 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00404: acc did not improve\n",
      "Epoch 405/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2313 - acc: 0.9344 - val_loss: 0.2241 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00405: acc did not improve\n",
      "Epoch 406/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2443 - acc: 0.9294 - val_loss: 0.2201 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00406: acc did not improve\n",
      "Epoch 407/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2447 - acc: 0.9285 - val_loss: 0.2218 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00407: acc did not improve\n",
      "Epoch 408/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2432 - acc: 0.9289 - val_loss: 0.2203 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00408: acc did not improve\n",
      "Epoch 409/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2477 - acc: 0.9278 - val_loss: 0.2008 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00409: acc did not improve\n",
      "Epoch 410/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2359 - acc: 0.9335 - val_loss: 0.1992 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00410: acc did not improve\n",
      "Epoch 411/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2408 - acc: 0.9300 - val_loss: 0.1987 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00411: acc did not improve\n",
      "Epoch 412/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2348 - acc: 0.9331 - val_loss: 0.2006 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00412: acc did not improve\n",
      "Epoch 413/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2462 - acc: 0.9289 - val_loss: 0.1976 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00413: acc did not improve\n",
      "Epoch 414/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2363 - acc: 0.9333 - val_loss: 0.2044 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00414: acc did not improve\n",
      "Epoch 415/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2570 - acc: 0.9248 - val_loss: 0.2077 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00415: acc did not improve\n",
      "Epoch 416/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2481 - acc: 0.9265 - val_loss: 0.2053 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00416: acc did not improve\n",
      "Epoch 417/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2496 - acc: 0.9263 - val_loss: 0.1989 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00417: acc did not improve\n",
      "Epoch 418/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2449 - acc: 0.9281 - val_loss: 0.2028 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00418: acc did not improve\n",
      "Epoch 419/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2493 - acc: 0.9276 - val_loss: 0.1998 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00419: acc did not improve\n",
      "Epoch 420/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2456 - acc: 0.9296 - val_loss: 0.2033 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00420: acc did not improve\n",
      "Epoch 421/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2409 - acc: 0.9307 - val_loss: 0.2295 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00421: acc did not improve\n",
      "Epoch 422/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2562 - acc: 0.9224 - val_loss: 0.2296 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00422: acc did not improve\n",
      "Epoch 423/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2507 - acc: 0.9263 - val_loss: 0.2184 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00423: acc did not improve\n",
      "Epoch 424/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2403 - acc: 0.9309 - val_loss: 0.2229 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00424: acc did not improve\n",
      "Epoch 425/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2357 - acc: 0.9322 - val_loss: 0.2173 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00425: acc did not improve\n",
      "Epoch 426/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2371 - acc: 0.9335 - val_loss: 0.2022 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00426: acc did not improve\n",
      "Epoch 427/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2325 - acc: 0.9340 - val_loss: 0.2030 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00427: acc did not improve\n",
      "Epoch 428/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2480 - acc: 0.9281 - val_loss: 0.2021 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00428: acc did not improve\n",
      "Epoch 429/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2375 - acc: 0.9307 - val_loss: 0.2418 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00429: acc did not improve\n",
      "Epoch 430/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2412 - acc: 0.9307 - val_loss: 0.2238 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00430: acc did not improve\n",
      "Epoch 431/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2295 - acc: 0.9364 - val_loss: 0.2342 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00431: acc improved from 0.93615 to 0.93637, saving model to best_model_LSTM\n",
      "Epoch 432/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2474 - acc: 0.9285 - val_loss: 0.2018 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00432: acc did not improve\n",
      "Epoch 433/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2346 - acc: 0.9342 - val_loss: 0.2049 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00433: acc did not improve\n",
      "Epoch 434/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2318 - acc: 0.9353 - val_loss: 0.2007 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00434: acc did not improve\n",
      "Epoch 435/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2420 - acc: 0.9302 - val_loss: 0.2187 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00435: acc did not improve\n",
      "Epoch 436/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2486 - acc: 0.9291 - val_loss: 0.1995 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00436: acc did not improve\n",
      "Epoch 437/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2471 - acc: 0.9294 - val_loss: 0.2019 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00437: acc did not improve\n",
      "Epoch 438/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2494 - acc: 0.9270 - val_loss: 0.2057 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00438: acc did not improve\n",
      "Epoch 439/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2442 - acc: 0.9305 - val_loss: 0.1998 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00439: acc did not improve\n",
      "Epoch 440/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2529 - acc: 0.9272 - val_loss: 0.2126 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00440: acc did not improve\n",
      "Epoch 441/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2524 - acc: 0.9276 - val_loss: 0.2069 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00441: acc did not improve\n",
      "Epoch 442/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2453 - acc: 0.9281 - val_loss: 0.2046 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00442: acc did not improve\n",
      "Epoch 443/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2367 - acc: 0.9337 - val_loss: 0.2108 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00443: acc did not improve\n",
      "Epoch 444/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2359 - acc: 0.9331 - val_loss: 0.2225 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00444: acc did not improve\n",
      "Epoch 445/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2393 - acc: 0.9316 - val_loss: 0.2173 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00445: acc did not improve\n",
      "Epoch 446/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2414 - acc: 0.9294 - val_loss: 0.2074 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00446: acc did not improve\n",
      "Epoch 447/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2443 - acc: 0.9313 - val_loss: 0.2015 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00447: acc did not improve\n",
      "Epoch 448/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2478 - acc: 0.9281 - val_loss: 0.2131 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00448: acc did not improve\n",
      "Epoch 449/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2498 - acc: 0.9278 - val_loss: 0.1997 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00449: acc did not improve\n",
      "Epoch 450/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2477 - acc: 0.9276 - val_loss: 0.2094 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00450: acc did not improve\n",
      "Epoch 451/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2444 - acc: 0.9285 - val_loss: 0.2020 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00451: acc did not improve\n",
      "Epoch 452/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2486 - acc: 0.9281 - val_loss: 0.1999 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00452: acc did not improve\n",
      "Epoch 453/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2431 - acc: 0.9320 - val_loss: 0.2080 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00453: acc did not improve\n",
      "Epoch 454/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2426 - acc: 0.9302 - val_loss: 0.2156 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00454: acc did not improve\n",
      "Epoch 455/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2358 - acc: 0.9340 - val_loss: 0.2081 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00455: acc did not improve\n",
      "Epoch 456/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2425 - acc: 0.9311 - val_loss: 0.2102 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00456: acc did not improve\n",
      "Epoch 457/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2372 - acc: 0.9331 - val_loss: 0.2050 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00457: acc did not improve\n",
      "Epoch 458/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2461 - acc: 0.9302 - val_loss: 0.2137 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00458: acc did not improve\n",
      "Epoch 459/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2393 - acc: 0.9322 - val_loss: 0.2080 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00459: acc did not improve\n",
      "Epoch 460/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2330 - acc: 0.9355 - val_loss: 0.2060 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00460: acc did not improve\n",
      "Epoch 461/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2424 - acc: 0.9298 - val_loss: 0.2048 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00461: acc did not improve\n",
      "Epoch 462/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2417 - acc: 0.9316 - val_loss: 0.2097 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00462: acc did not improve\n",
      "Epoch 463/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2487 - acc: 0.9267 - val_loss: 0.2179 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00463: acc did not improve\n",
      "Epoch 464/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2375 - acc: 0.9318 - val_loss: 0.2082 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00464: acc did not improve\n",
      "Epoch 465/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2429 - acc: 0.9285 - val_loss: 0.2073 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00465: acc did not improve\n",
      "Epoch 466/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2348 - acc: 0.9329 - val_loss: 0.1956 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00466: acc did not improve\n",
      "Epoch 467/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2434 - acc: 0.9298 - val_loss: 0.2202 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00467: acc did not improve\n",
      "Epoch 468/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2420 - acc: 0.9309 - val_loss: 0.2241 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00468: acc did not improve\n",
      "Epoch 469/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2419 - acc: 0.9305 - val_loss: 0.2322 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00469: acc did not improve\n",
      "Epoch 470/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2514 - acc: 0.9272 - val_loss: 0.2385 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00470: acc did not improve\n",
      "Epoch 471/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2493 - acc: 0.9270 - val_loss: 0.2118 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00471: acc did not improve\n",
      "Epoch 472/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2374 - acc: 0.9322 - val_loss: 0.2022 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00472: acc did not improve\n",
      "Epoch 473/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2479 - acc: 0.9283 - val_loss: 0.2349 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00473: acc did not improve\n",
      "Epoch 474/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2442 - acc: 0.9287 - val_loss: 0.2060 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00474: acc did not improve\n",
      "Epoch 475/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2426 - acc: 0.9296 - val_loss: 0.1999 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00475: acc did not improve\n",
      "Epoch 476/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2346 - acc: 0.9344 - val_loss: 0.2032 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00476: acc did not improve\n",
      "Epoch 477/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2323 - acc: 0.9342 - val_loss: 0.2026 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00477: acc did not improve\n",
      "Epoch 478/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2386 - acc: 0.9322 - val_loss: 0.2083 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00478: acc did not improve\n",
      "Epoch 479/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2393 - acc: 0.9322 - val_loss: 0.2222 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00479: acc did not improve\n",
      "Epoch 480/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2422 - acc: 0.9302 - val_loss: 0.2000 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00480: acc did not improve\n",
      "Epoch 481/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2354 - acc: 0.9329 - val_loss: 0.2060 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00481: acc did not improve\n",
      "Epoch 482/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2560 - acc: 0.9250 - val_loss: 0.2144 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00482: acc did not improve\n",
      "Epoch 483/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2376 - acc: 0.9307 - val_loss: 0.2179 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00483: acc did not improve\n",
      "Epoch 484/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2378 - acc: 0.9307 - val_loss: 0.2203 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00484: acc did not improve\n",
      "Epoch 485/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2438 - acc: 0.9294 - val_loss: 0.2067 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00485: acc did not improve\n",
      "Epoch 486/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2394 - acc: 0.9316 - val_loss: 0.1996 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00486: acc did not improve\n",
      "Epoch 487/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2357 - acc: 0.9329 - val_loss: 0.2225 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00487: acc did not improve\n",
      "Epoch 488/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2288 - acc: 0.9357 - val_loss: 0.1997 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00488: acc did not improve\n",
      "Epoch 489/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2285 - acc: 0.9355 - val_loss: 0.2084 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00489: acc did not improve\n",
      "Epoch 490/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2291 - acc: 0.9342 - val_loss: 0.2016 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00490: acc did not improve\n",
      "Epoch 491/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2260 - acc: 0.9361 - val_loss: 0.2053 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00491: acc did not improve\n",
      "Epoch 492/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2478 - acc: 0.9270 - val_loss: 0.2240 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00492: acc did not improve\n",
      "Epoch 493/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2408 - acc: 0.9309 - val_loss: 0.2134 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00493: acc did not improve\n",
      "Epoch 494/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2472 - acc: 0.9291 - val_loss: 0.2101 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00494: acc did not improve\n",
      "Epoch 495/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2395 - acc: 0.9326 - val_loss: 0.2203 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00495: acc did not improve\n",
      "Epoch 496/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2476 - acc: 0.9272 - val_loss: 0.2089 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00496: acc did not improve\n",
      "Epoch 497/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2432 - acc: 0.9307 - val_loss: 0.1975 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00497: acc did not improve\n",
      "Epoch 498/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2328 - acc: 0.9340 - val_loss: 0.1987 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00498: acc did not improve\n",
      "Epoch 499/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2318 - acc: 0.9357 - val_loss: 0.2152 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00499: acc did not improve\n",
      "Epoch 500/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2375 - acc: 0.9331 - val_loss: 0.2316 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00500: acc did not improve\n",
      "Epoch 501/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2491 - acc: 0.9261 - val_loss: 0.2238 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00501: acc did not improve\n",
      "Epoch 502/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2411 - acc: 0.9313 - val_loss: 0.1984 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00502: acc did not improve\n",
      "Epoch 503/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2490 - acc: 0.9285 - val_loss: 0.1959 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00503: acc did not improve\n",
      "Epoch 504/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2447 - acc: 0.9294 - val_loss: 0.2066 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00504: acc did not improve\n",
      "Epoch 505/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2437 - acc: 0.9305 - val_loss: 0.2032 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00505: acc did not improve\n",
      "Epoch 506/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2377 - acc: 0.9313 - val_loss: 0.2009 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00506: acc did not improve\n",
      "Epoch 507/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2376 - acc: 0.9326 - val_loss: 0.2131 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00507: acc did not improve\n",
      "Epoch 508/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2290 - acc: 0.9357 - val_loss: 0.2142 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00508: acc did not improve\n",
      "Epoch 509/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2378 - acc: 0.9316 - val_loss: 0.2083 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00509: acc did not improve\n",
      "Epoch 510/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2412 - acc: 0.9302 - val_loss: 0.2236 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00510: acc did not improve\n",
      "Epoch 511/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2401 - acc: 0.9305 - val_loss: 0.2032 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00511: acc did not improve\n",
      "Epoch 512/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2396 - acc: 0.9316 - val_loss: 0.2116 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00512: acc did not improve\n",
      "Epoch 513/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2439 - acc: 0.9291 - val_loss: 0.1988 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00513: acc did not improve\n",
      "Epoch 514/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2288 - acc: 0.9375 - val_loss: 0.2052 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00514: acc improved from 0.93637 to 0.93746, saving model to best_model_LSTM\n",
      "Epoch 515/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2376 - acc: 0.9326 - val_loss: 0.2098 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00515: acc did not improve\n",
      "Epoch 516/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2366 - acc: 0.9335 - val_loss: 0.1989 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00516: acc did not improve\n",
      "Epoch 517/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2356 - acc: 0.9340 - val_loss: 0.1993 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00517: acc did not improve\n",
      "Epoch 518/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2284 - acc: 0.9357 - val_loss: 0.2168 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00518: acc did not improve\n",
      "Epoch 519/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2387 - acc: 0.9320 - val_loss: 0.2240 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00519: acc did not improve\n",
      "Epoch 520/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2352 - acc: 0.9333 - val_loss: 0.2082 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00520: acc did not improve\n",
      "Epoch 521/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2293 - acc: 0.9361 - val_loss: 0.2021 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00521: acc did not improve\n",
      "Epoch 522/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2471 - acc: 0.9283 - val_loss: 0.3240 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00522: acc did not improve\n",
      "Epoch 523/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2779 - acc: 0.9165 - val_loss: 0.3268 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00523: acc did not improve\n",
      "Epoch 524/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2849 - acc: 0.9127 - val_loss: 0.3233 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00524: acc did not improve\n",
      "Epoch 525/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2792 - acc: 0.9145 - val_loss: 0.3239 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00525: acc did not improve\n",
      "Epoch 526/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2747 - acc: 0.9145 - val_loss: 0.3251 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00526: acc did not improve\n",
      "Epoch 527/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2800 - acc: 0.9108 - val_loss: 0.3274 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00527: acc did not improve\n",
      "Epoch 528/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2739 - acc: 0.9154 - val_loss: 0.3261 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00528: acc did not improve\n",
      "Epoch 529/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2795 - acc: 0.9132 - val_loss: 0.3236 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00529: acc did not improve\n",
      "Epoch 530/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2840 - acc: 0.9123 - val_loss: 0.3296 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00530: acc did not improve\n",
      "Epoch 531/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2867 - acc: 0.9095 - val_loss: 0.3242 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00531: acc did not improve\n",
      "Epoch 532/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2809 - acc: 0.9121 - val_loss: 0.3278 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00532: acc did not improve\n",
      "Epoch 533/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2832 - acc: 0.9121 - val_loss: 0.3228 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00533: acc did not improve\n",
      "Epoch 534/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2814 - acc: 0.9127 - val_loss: 0.3212 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00534: acc did not improve\n",
      "Epoch 535/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2823 - acc: 0.9108 - val_loss: 0.3255 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00535: acc did not improve\n",
      "Epoch 536/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2742 - acc: 0.9158 - val_loss: 0.3253 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00536: acc did not improve\n",
      "Epoch 537/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2742 - acc: 0.9154 - val_loss: 0.3250 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00537: acc did not improve\n",
      "Epoch 538/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2973 - acc: 0.9060 - val_loss: 0.3336 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00538: acc did not improve\n",
      "Epoch 539/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2829 - acc: 0.9121 - val_loss: 0.3347 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00539: acc did not improve\n",
      "Epoch 540/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2843 - acc: 0.9127 - val_loss: 0.3245 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00540: acc did not improve\n",
      "Epoch 541/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2827 - acc: 0.9125 - val_loss: 0.3232 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00541: acc did not improve\n",
      "Epoch 542/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2766 - acc: 0.9145 - val_loss: 0.3232 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00542: acc did not improve\n",
      "Epoch 543/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2681 - acc: 0.9195 - val_loss: 0.2143 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00543: acc did not improve\n",
      "Epoch 544/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2442 - acc: 0.9283 - val_loss: 0.2012 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00544: acc did not improve\n",
      "Epoch 545/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2402 - acc: 0.9313 - val_loss: 0.2046 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00545: acc did not improve\n",
      "Epoch 546/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2349 - acc: 0.9331 - val_loss: 0.2030 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00546: acc did not improve\n",
      "Epoch 547/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2502 - acc: 0.9272 - val_loss: 0.3257 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00547: acc did not improve\n",
      "Epoch 548/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2858 - acc: 0.9114 - val_loss: 0.3248 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00548: acc did not improve\n",
      "Epoch 549/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2816 - acc: 0.9112 - val_loss: 0.3300 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00549: acc did not improve\n",
      "Epoch 550/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2772 - acc: 0.9136 - val_loss: 0.3225 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00550: acc did not improve\n",
      "Epoch 551/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2773 - acc: 0.9123 - val_loss: 0.3284 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00551: acc did not improve\n",
      "Epoch 552/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2776 - acc: 0.9127 - val_loss: 0.3246 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00552: acc did not improve\n",
      "Epoch 553/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2658 - acc: 0.9178 - val_loss: 0.3373 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00553: acc did not improve\n",
      "Epoch 554/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2807 - acc: 0.9127 - val_loss: 0.3248 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00554: acc did not improve\n",
      "Epoch 555/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2828 - acc: 0.9114 - val_loss: 0.3245 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00555: acc did not improve\n",
      "Epoch 556/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2704 - acc: 0.9143 - val_loss: 0.3280 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00556: acc did not improve\n",
      "Epoch 557/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2801 - acc: 0.9112 - val_loss: 0.3253 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00557: acc did not improve\n",
      "Epoch 558/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2807 - acc: 0.9125 - val_loss: 0.3242 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00558: acc did not improve\n",
      "Epoch 559/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2726 - acc: 0.9167 - val_loss: 0.3221 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00559: acc did not improve\n",
      "Epoch 560/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2696 - acc: 0.9167 - val_loss: 0.3299 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00560: acc did not improve\n",
      "Epoch 561/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2687 - acc: 0.9189 - val_loss: 0.3281 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00561: acc did not improve\n",
      "Epoch 562/600\n",
      "4573/4573 [==============================] - 0s 86us/step - loss: 0.2801 - acc: 0.9130 - val_loss: 0.3269 - val_acc: 0.8998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00562: acc did not improve\n",
      "Epoch 563/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2725 - acc: 0.9154 - val_loss: 0.3213 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00563: acc did not improve\n",
      "Epoch 564/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2820 - acc: 0.9114 - val_loss: 0.3639 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00564: acc did not improve\n",
      "Epoch 565/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2856 - acc: 0.9127 - val_loss: 0.3260 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00565: acc did not improve\n",
      "Epoch 566/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2731 - acc: 0.9160 - val_loss: 0.3243 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00566: acc did not improve\n",
      "Epoch 567/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2736 - acc: 0.9138 - val_loss: 0.3225 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00567: acc did not improve\n",
      "Epoch 568/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2746 - acc: 0.9141 - val_loss: 0.3230 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00568: acc did not improve\n",
      "Epoch 569/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2754 - acc: 0.9136 - val_loss: 0.3239 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00569: acc did not improve\n",
      "Epoch 570/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2805 - acc: 0.9121 - val_loss: 0.3245 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00570: acc did not improve\n",
      "Epoch 571/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2716 - acc: 0.9171 - val_loss: 0.3254 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00571: acc did not improve\n",
      "Epoch 572/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2692 - acc: 0.9171 - val_loss: 0.3231 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00572: acc did not improve\n",
      "Epoch 573/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2731 - acc: 0.9145 - val_loss: 0.3294 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00573: acc did not improve\n",
      "Epoch 574/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2768 - acc: 0.9134 - val_loss: 0.3313 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00574: acc did not improve\n",
      "Epoch 575/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2782 - acc: 0.9134 - val_loss: 0.3259 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00575: acc did not improve\n",
      "Epoch 576/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2849 - acc: 0.9099 - val_loss: 0.3325 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00576: acc did not improve\n",
      "Epoch 577/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2723 - acc: 0.9158 - val_loss: 0.3269 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00577: acc did not improve\n",
      "Epoch 578/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2681 - acc: 0.9165 - val_loss: 0.3227 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00578: acc did not improve\n",
      "Epoch 579/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2717 - acc: 0.9156 - val_loss: 0.3245 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00579: acc did not improve\n",
      "Epoch 580/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2737 - acc: 0.9160 - val_loss: 0.3260 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00580: acc did not improve\n",
      "Epoch 581/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2768 - acc: 0.9145 - val_loss: 0.3247 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00581: acc did not improve\n",
      "Epoch 582/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2754 - acc: 0.9130 - val_loss: 0.3299 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00582: acc did not improve\n",
      "Epoch 583/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2754 - acc: 0.9149 - val_loss: 0.3295 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00583: acc did not improve\n",
      "Epoch 584/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2695 - acc: 0.9167 - val_loss: 0.3270 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00584: acc did not improve\n",
      "Epoch 585/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2797 - acc: 0.9127 - val_loss: 0.3211 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00585: acc did not improve\n",
      "Epoch 586/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2769 - acc: 0.9130 - val_loss: 0.3243 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00586: acc did not improve\n",
      "Epoch 587/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2774 - acc: 0.9127 - val_loss: 0.3556 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00587: acc did not improve\n",
      "Epoch 588/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2849 - acc: 0.9101 - val_loss: 0.3255 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00588: acc did not improve\n",
      "Epoch 589/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2715 - acc: 0.9167 - val_loss: 0.3305 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00589: acc did not improve\n",
      "Epoch 590/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2789 - acc: 0.9123 - val_loss: 0.3224 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00590: acc did not improve\n",
      "Epoch 591/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2719 - acc: 0.9160 - val_loss: 0.3243 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00591: acc did not improve\n",
      "Epoch 592/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2756 - acc: 0.9145 - val_loss: 0.3229 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00592: acc did not improve\n",
      "Epoch 593/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2728 - acc: 0.9156 - val_loss: 0.3231 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00593: acc did not improve\n",
      "Epoch 594/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2699 - acc: 0.9160 - val_loss: 0.3244 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00594: acc did not improve\n",
      "Epoch 595/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2787 - acc: 0.9123 - val_loss: 0.3238 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00595: acc did not improve\n",
      "Epoch 596/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2744 - acc: 0.9147 - val_loss: 0.3291 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00596: acc did not improve\n",
      "Epoch 597/600\n",
      "4573/4573 [==============================] - 0s 87us/step - loss: 0.2753 - acc: 0.9147 - val_loss: 0.3330 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00597: acc did not improve\n",
      "Epoch 598/600\n",
      "4573/4573 [==============================] - 0s 88us/step - loss: 0.2709 - acc: 0.9167 - val_loss: 0.3311 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00598: acc did not improve\n",
      "Epoch 599/600\n",
      "4573/4573 [==============================] - 0s 89us/step - loss: 0.2688 - acc: 0.9178 - val_loss: 0.3234 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00599: acc did not improve\n",
      "Epoch 600/600\n",
      "4573/4573 [==============================] - 0s 91us/step - loss: 0.2770 - acc: 0.9143 - val_loss: 0.3237 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00600: acc did not improve\n"
     ]
    }
   ],
   "source": [
    "ltsm = Sequential()\n",
    "ltsm.add(LSTM(128, input_shape=(3, len(X_train[0][0])), return_sequences=True,\n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "    # model.add(LSTM(hparams.nb_rnn_units_l2, return_sequences=True, dropout=hparams.drop_rate,\n",
    "    #                recurrent_dropout=hparams.drop_rate))\n",
    "ltsm.add(LSTM(2))\n",
    "ltsm.add(Dense(1, activation='sigmoid'))\n",
    "ltsm.summary()\n",
    "\n",
    "ltsm.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(0.006),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "save_model_path = 'best_model_LSTM'\n",
    "earlystopping = EarlyStopping(monitor = 'val_acc', patience=10)\n",
    "modelcheckpoint = ModelCheckpoint(save_model_path, monitor = 'acc', verbose = 1, save_best_only = True)\n",
    "\n",
    "history_lstm = ltsm.fit(X_train, Y_train, batch_size=128, epochs = 600, validation_split = 0.1, callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6486/6486 [==============================] - 1s 146us/step\n",
      "0.8977798335794089\n"
     ]
    }
   ],
   "source": [
    "ltsm = load_model(save_model_path)\n",
    "accuracy = ltsm.evaluate(X_test, Y_test)[1]\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history_lstm.history[\"acc\"], label = 'LSTM')\n",
    "plt.plot(history_FFW.history[\"acc\"], label = \"FFW\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Model accuracy during training phase\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = getDataset(TRAIN_DATA_PATH, flatten=True)\n",
    "X_test, Y_test = getDataset(TEST_DATA_PATH, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9470680834317198\n",
      "0.8558433549182856\n"
     ]
    }
   ],
   "source": [
    "SVM = SVC(gamma=1e-05, kernel='rbf', C=4)\n",
    "SVM.fit(X_train, Y_train)\n",
    "\n",
    "train_score = SVM.score(X_train, Y_train)\n",
    "test_score = SVM.score(X_test, Y_test) \n",
    "print train_score\n",
    "print test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = getDataset(TRAIN_DATA_PATH, flatten=True)\n",
    "X_test, Y_test = getDataset(TEST_DATA_PATH, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9000393545848091\n",
      "0.7180080172679618\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(C=1e5)\n",
    "LR.fit(X_train, Y_train)\n",
    "\n",
    "train_score = LR.score(X_train, Y_train)\n",
    "test_score = LR.score(X_test, Y_test)\n",
    "print train_score\n",
    "print test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9970484061393152\n",
      "0.8304039469626888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=5)\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "train_score = RF.score(X_train, Y_train)\n",
    "test_score = RF.score(X_test, Y_test)\n",
    "print train_score\n",
    "print test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floor Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of this code has been taken from author official GitHub (mentionnned in his paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_io_intervals(dfa, min_similarity):\n",
    "    # ---------------\n",
    "    # define IO vector mask\n",
    "    target_vector_in_out = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "    target_vector_in_out = np.add(target_vector_in_out, 1).tolist()\n",
    "    target_vector_out_in = target_vector_in_out[::-1]\n",
    "    window_size = len(target_vector_in_out)\n",
    "\n",
    "    preds = dfa['indoors_prediction'].tolist()\n",
    "    # ---------------\n",
    "    # find matches\n",
    "    matches = []\n",
    "    for i in range(0, len(preds) - window_size):\n",
    "        vec = preds[i: i + window_size]\n",
    "        vec = np.add(vec, 1)\n",
    "        \n",
    "        dist_a = distance.jaccard(target_vector_in_out, vec)\n",
    "        dist_b = distance.jaccard(vec, target_vector_out_in)\n",
    "        \n",
    "        if dist_a >= min_similarity:\n",
    "            matches.append(i)\n",
    "\n",
    "        elif dist_b >= min_similarity:\n",
    "            matches.append(i)\n",
    "\n",
    "    sorted(matches)\n",
    "    \n",
    "    # ---------------\n",
    "    # Group matches\n",
    "    merged = [(matches[0], matches[0] + 2)]\n",
    "    for start in matches[1:]:\n",
    "        end = start+2\n",
    "\n",
    "        merged_start, merged_end = merged[-1]\n",
    "\n",
    "        if (start <= merged_end):\n",
    "            merged[-1] = (merged_start, max(merged_end, end))\n",
    "\n",
    "        else:\n",
    "            merged.append((start, end))\n",
    "        \n",
    "    # --------------\n",
    "    # FIND PEAKS\n",
    "    #print('Merged interval groups:')\n",
    "    #print(merged)\n",
    "    stack = []\n",
    "    for x, y in merged:\n",
    "        avg = np.mean([x,y])\n",
    "        stack.append(avg)\n",
    "\n",
    "    #print('\\nFinal Transition locations (ith datapoint):')\n",
    "    #print(stack)\n",
    "    peaks_detected_by_classifier = stack\n",
    "    return peaks_detected_by_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_transition_dp(dfa, peaks_detected_by_classifier):\n",
    "    last_transition_index = int(peaks_detected_by_classifier[-1])\n",
    "    dp = dfa.iloc[[last_transition_index]]\n",
    "    return dp, last_transition_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dfs(frames,model):\n",
    "    accuracies = []\n",
    "    predicted = []\n",
    "    for df in frames:\n",
    "        X, Y = create_test_data(df, X_features =\n",
    "                            ['gps_vertical_accuracy', \n",
    "                             'gps_horizontal_accuracy', \n",
    "                             'gps_speed', \n",
    "                             'rssi_strength', \n",
    "                             'magnet_total'], \n",
    "                            Y_label='indoors', model=model)\n",
    "        df, accuracy = predict(model, df, X, Y)\n",
    "        predicted.append(df)\n",
    "        accuracies.append(float(\"{0:.2f}\".format(accuracy)))\n",
    "    avg_acc = np.mean(accuracies)\n",
    "    print('avg acc NN: ', float(\"{0:.3f}\".format(avg_acc)))\n",
    "    return predicted, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, df, X, Y, window_length=3):\n",
    "    \n",
    "    df_with_window = df[0:-window_length]\n",
    "    if model == 'LSTM':\n",
    "        preds = ltsm.predict(X)\n",
    "        accuracy = ltsm.evaluate(X, Y, verbose=0)[1]\n",
    "        #results = np.argmax(preds, axis=1).reshape(len(preds), 1)\n",
    "        #results = np.ones(len(preds))\n",
    "        results = (preds > 0.5).astype(int)\n",
    "    if model == 'FFW':\n",
    "        preds = FFW.predict(X)\n",
    "        accuracy = FFW.evaluate(X, Y, verbose=0)[1]\n",
    "        #results = np.argmax(preds, axis=1).reshape(len(preds), 1)\n",
    "        results = (preds > 0.5).astype(int)\n",
    "    if model == 'SVM':\n",
    "        preds = SVM.predict(X)\n",
    "        results = preds.reshape(len(X), 1)\n",
    "        df_with_window['indoors_prediction'] = results\n",
    "        accuracy = df_with_window[df_with_window.indoors == df_with_window.indoors_prediction].count()['indoors'] / float(len(df_with_window))\n",
    "    if model == 'RF':\n",
    "        preds = RF.predict(X)\n",
    "        results = preds.reshape(len(X), 1)\n",
    "        df_with_window['indoors_prediction'] = results\n",
    "        accuracy = df_with_window[df_with_window.indoors == df_with_window.indoors_prediction].count()['indoors'] / float(len(df_with_window))\n",
    "    if model == 'LR':\n",
    "        preds = LR.predict(X)\n",
    "        results = preds.reshape(len(X), 1)\n",
    "        df_with_window['indoors_prediction'] = results\n",
    "        accuracy = df_with_window[df_with_window.indoors == df_with_window.indoors_prediction].count()['indoors'] / float(len(df_with_window))\n",
    "        \n",
    "    \n",
    "    # save to new df\n",
    "    df_with_window['indoors_prediction'] = results\n",
    "        \n",
    "\n",
    "    return df_with_window, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(df, X_features, Y_label, model):\n",
    "    X = df[X_features]\n",
    "    Y = df[[Y_label]]\n",
    "\n",
    "    X = X.as_matrix()\n",
    "    Y = Y.as_matrix()\n",
    "\n",
    "    new_X = []\n",
    "    new_Y = np.zeros((len(X) - WINDOW_LENGTH, 1))\n",
    "    arr_i = 0\n",
    "    side_size = int((WINDOW_LENGTH - 1) /2)\n",
    "    for i in range(side_size, len(X)):\n",
    "        i_start = i - side_size\n",
    "        i_end = i + side_size + 1\n",
    "        y_i = i\n",
    "        dps = X[i_start:i_end, :]\n",
    "        new_x = dps\n",
    "        if model !='LSTM':\n",
    "            new_x = dps.flatten()\n",
    "        new_y = Y[y_i]\n",
    "        if i_end >= len(X):\n",
    "            break\n",
    "        new_X.append(new_x)\n",
    "        new_Y[arr_i] = new_y\n",
    "        arr_i += 1\n",
    "    \n",
    "    new_X = np.asarray(new_X)\n",
    "    return new_X, new_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(model, data_path):\n",
    "    frames = []\n",
    "    frames_names = []\n",
    "    for file_name in os.listdir(data_path):\n",
    "        if 'csv' in file_name:\n",
    "        #if 'csv' in file_name and '_' in file_name:\n",
    "            in_path = '%s/%s' % (data_path, file_name)\n",
    "            df = pd.read_csv(in_path)\n",
    "            df = df.fillna(0)\n",
    "            frames.append(df)\n",
    "            frames_names.append(file_name)\n",
    "    # add weather data\n",
    "    for df in frames:\n",
    "        df['weather_pressure'] = [100] * len(df)\n",
    "    \n",
    "    frames, accuracies = predict_dfs(frames,model)\n",
    "    return frames, frames_names\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_transition_point(dfa, last_transition_index):\n",
    "    num_points_around_transition = 10\n",
    "    lookback_window = 20\n",
    "    #print('last transition idx: ', last_transition_index)\n",
    "    \n",
    "    before = dfa[last_transition_index - num_points_around_transition : last_transition_index]\n",
    "    after = dfa[last_transition_index : last_transition_index + num_points_around_transition]\n",
    "    before_mean_pressure = np.mean(before.baro_pressure)\n",
    "    after_mean_pressure = np.mean(after.baro_pressure)\n",
    "    direction_change = \"pos\" if before_mean_pressure < after_mean_pressure else \"neg\"\n",
    "    if last_transition_index < lookback_window:\n",
    "        return dfa.iloc[[0]], -1\n",
    "    if direction_change is \"pos\":\n",
    "        optimal_point = np.argmin(dfa.baro_pressure[last_transition_index - lookback_window : last_transition_index]) \n",
    "    else:\n",
    "        optimal_point = np.argmax(dfa.baro_pressure[last_transition_index - lookback_window : last_transition_index]) \n",
    "\n",
    "    #print('optimal transition idx: ', optimal_point)\n",
    "    dp = dfa.iloc[[optimal_point]]\n",
    "    \n",
    "    return dp, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_current_floor(dp, last_dp, floor_height_meters):\n",
    "    # pressure readings at time of last transition\n",
    "    transition_device_pressure = dp.baro_pressure.values[0]\n",
    "    weather_pressure_at_transition = dp.weather_pressure.values[0]\n",
    "\n",
    "    # pressure readings at current point\n",
    "    current_device_pressure = last_dp.baro_pressure.values[0]\n",
    "    current_weather_pressure = last_dp.weather_pressure.values[0]\n",
    "\n",
    "    # calculate weather pressure delta\n",
    "    weather_pressure_delta = current_weather_pressure - weather_pressure_at_transition\n",
    "\n",
    "    # calculate device pressure delta\n",
    "    weather_adjusted_start_device_pressure = transition_device_pressure + weather_pressure_delta\n",
    "\n",
    "    # this is the difference between pressures formula\n",
    "    # the answer is in meters\n",
    "    total_meter_change = 44330 * (1 - (current_device_pressure/weather_adjusted_start_device_pressure)**(1/5.255))\n",
    "\n",
    "    # floor detection rule\n",
    "    floor_delta = int(total_meter_change / floor_height_meters)\n",
    "    if floor_delta >= 0:\n",
    "        current_floor = 1 + floor_delta\n",
    "    else:\n",
    "        current_floor = floor_delta\n",
    "    \n",
    "    return current_floor, total_meter_change, floor_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_io_status(dfa, last_transition_index):\n",
    "    after_last_transition_points = dfa[last_transition_index : ]\n",
    "    indoor_preds = after_last_transition_points.indoors_prediction\n",
    "    pcnt_inside = indoor_preds[indoor_preds == 1].sum() / float(len(indoor_preds))\n",
    "    inside_status = 'indoors' if pcnt_inside > 0.5 else 'outdoors'\n",
    "    return inside_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_floor(test_name):\n",
    "    real_floor = test_name.split('_')\n",
    "    #print(real_floor)\n",
    "    real_floor_start = int(real_floor[2])\n",
    "    real_floor_end = int(real_floor[-1].split('.')[0])\n",
    "    floor_delta = real_floor_end - real_floor_start\n",
    "    #floor_delta = floor_delta + 1 if real_floor_start < real_floor_end else floor_delta - 1\n",
    "    return floor_delta, real_floor_start, real_floor_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_floor(path, model, floor_height_meters=4.02, heights=None):\n",
    "    results = {'exact_floor':0, 'near_miss':0, 'large_miss':0}\n",
    "    number_wrong_csv = 0\n",
    "    frames, frames_names = load_data(model, path)\n",
    "    for i, dfa in enumerate(frames):\n",
    "        dfa = frames[i]\n",
    "        test_name = frames_names[i]\n",
    "        if heights is not None:\n",
    "            test_start = test_name.split('_')[0]\n",
    "            floor_height_meters = heights[test_start]\n",
    "        \n",
    "        # detect peaks\n",
    "        peaks_detected_by_classifier = find_io_intervals(dfa, min_similarity=0.6)\n",
    "        # find last point a transition happened\n",
    "        last_transition_dp, last_transition_index = get_last_transition_dp(dfa, peaks_detected_by_classifier)\n",
    "        #print (len(dfa) - last_transition_index)\n",
    "        # last dp of user loc\n",
    "        last_dp = dfa.iloc[[-1]]\n",
    "        # find point where the optimal transition happened\n",
    "        # this is the loéwest point around a transition window\n",
    "        optimal_trans_dp, return_code = find_optimal_transition_point(dfa, last_transition_index)\n",
    "        if return_code == -1:\n",
    "            number_wrong_csv += 1\n",
    "            continue\n",
    "        \n",
    "        # make floor pred\n",
    "        current_floor, total_meter_change, predicted_floor_delta = predict_current_floor(optimal_trans_dp, last_dp, floor_height_meters=floor_height_meters)\n",
    "        \n",
    "        # determine if indoors or not\n",
    "        io_status = get_io_status(dfa, last_transition_index)\n",
    "\n",
    "        # print real floor info\n",
    "        floor_delta, real_floor_start, real_floor_end = ground_truth_floor(test_name)\n",
    "        #flr_heights.append(total_meter_change / floor_delta)\n",
    "        if floor_delta == predicted_floor_delta:\n",
    "            results['exact_floor'] += 1\n",
    "        elif floor_delta - 1 <= predicted_floor_delta <= floor_delta + 1:\n",
    "            results['near_miss'] += 1\n",
    "        else:\n",
    "            results['large_miss'] += 1\n",
    "        #print {'pred_delta': predicted_floor_delta, 'predicted': current_floor, 'real_delta': floor_delta, 'name': test_name, 'test_start': real_floor_start, 'test_end': real_floor_end}\n",
    "    print \"Number of experiments: \"+str(i+1-number_wrong_csv)\n",
    "    print \"Exact Floor: \"+str(results['exact_floor'] / float(i+1-number_wrong_csv))\n",
    "    print \"Floor +- 1: \"+str(results['near_miss'] / float(i+1-number_wrong_csv))\n",
    "    print \"Floor > 1: \"+str(results['large_miss'] / float(i+1-number_wrong_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JACCARD DISTANCE = 0.6 , LOOKBACK WINDOW = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('avg acc NN: ', 0.854)\n",
      "Number of experiments: 63\n",
      "Exact Floor: 1.0\n",
      "Floor +- 1: 0.0\n",
      "Floor > 1: 0.0\n"
     ]
    }
   ],
   "source": [
    "predict_floor(TEST_DATA_PATH, 'LSTM', heights={'gsb': 3.8, 'mudd': 3.4, 'noco': 4.2, 'ssw': 3.9, 'rock': 3.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('avg acc NN: ', 0.854)\n",
      "Number of experiments: 63\n",
      "Exact Floor: 0.634920634921\n",
      "Floor +- 1: 0.365079365079\n",
      "Floor > 1: 0.0\n"
     ]
    }
   ],
   "source": [
    "predict_floor(TEST_DATA_PATH, 'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('avg acc NN: ', 0.897)\n",
      "Number of experiments: 61\n",
      "Exact Floor: 1.0\n",
      "Floor +- 1: 0.0\n",
      "Floor > 1: 0.0\n"
     ]
    }
   ],
   "source": [
    "predict_floor(TEST_DATA_PATH, 'FFW', heights={'gsb': 3.8, 'mudd': 3.4, 'noco': 4.2, 'ssw': 3.9, 'rock': 3.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('avg acc NN: ', 0.897)\n",
      "Number of experiments: 61\n",
      "Exact Floor: 0.639344262295\n",
      "Floor +- 1: 0.360655737705\n",
      "Floor > 1: 0.0\n"
     ]
    }
   ],
   "source": [
    "predict_floor(TEST_DATA_PATH, 'FFW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('avg acc NN: ', 0.873)\n",
      "Number of experiments: 63\n",
      "Exact Floor: 1.0\n",
      "Floor +- 1: 0.0\n",
      "Floor > 1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "predict_floor(TEST_DATA_PATH, 'SVM', heights={'gsb': 3.8, 'mudd': 3.4, 'noco': 4.2, 'ssw': 3.9, 'rock': 3.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('avg acc NN: ', 0.873)\n",
      "Number of experiments: 63\n",
      "Exact Floor: 0.619047619048\n",
      "Floor +- 1: 0.380952380952\n",
      "Floor > 1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "predict_floor(TEST_DATA_PATH, 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('avg acc NN: ', 0.825)\n",
      "Number of experiments: 56\n",
      "Exact Floor: 1.0\n",
      "Floor +- 1: 0.0\n",
      "Floor > 1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "predict_floor(TEST_DATA_PATH, 'RF', heights={'gsb': 3.8, 'mudd': 3.4, 'noco': 4.2, 'ssw': 3.9, 'rock': 3.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('avg acc NN: ', 0.825)\n",
      "Number of experiments: 56\n",
      "Exact Floor: 0.625\n",
      "Floor +- 1: 0.375\n",
      "Floor > 1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "predict_floor(TEST_DATA_PATH, 'RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('avg acc NN: ', 0.671)\n",
      "Number of experiments: 63\n",
      "Exact Floor: 1.0\n",
      "Floor +- 1: 0.0\n",
      "Floor > 1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "predict_floor(TEST_DATA_PATH, 'LR', heights={'gsb': 3.8, 'mudd': 3.4, 'noco': 4.2, 'ssw': 3.9, 'rock': 3.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/maxencehull/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('avg acc NN: ', 0.671)\n",
      "Number of experiments: 63\n",
      "Exact Floor: 0.634920634921\n",
      "Floor +- 1: 0.365079365079\n",
      "Floor > 1: 0.0\n"
     ]
    }
   ],
   "source": [
    "predict_floor(TEST_DATA_PATH, 'LR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
